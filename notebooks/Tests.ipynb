{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T08:29:56.064390Z",
     "start_time": "2020-06-08T08:29:56.054211Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random \n",
    "import functools\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import albumentations as albu\n",
    "import photosynthesis_metrics as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T08:30:20.681380Z",
     "start_time": "2020-06-08T08:30:20.654901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Mon Jun 08 2020 \n",
      "\n",
      "CPython 3.6.9\n",
      "IPython 7.8.0\n",
      "\n",
      "numpy 1.17.0\n",
      "torch 1.5.0\n",
      "albumentations 0.4.5\n",
      "photosynthesis_metrics 0.3.0\n",
      "\n",
      "compiler   : GCC 8.4.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-99-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "# Fix to be able to import python modules inside a notebook\n",
    "os.chdir('..')\n",
    "\n",
    "# Useful extensions\n",
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,torch,albumentations,photosynthesis_metrics\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Nice plot formating\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T12:24:03.103357Z",
     "start_time": "2020-04-26T12:24:03.099630Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist = torchvision.datasets.MNIST(\"../datasets\", train=True, download=True)\n",
    "# cifar10 = torchvision.datasets.CIFAR10(\"../datasets\", download=True)\n",
    "# cifar100 = torchvision.datasets.CIFAR100(\"../datasets\", download=True)\n",
    "# fashin_mnist = torchvision.datasets.FashionMNIST(\"datasets\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T17:41:48.647750Z",
     "start_time": "2020-06-03T17:41:24.437192Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget -P datasets/ http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "# !wget -P datasets/ http://vllab.ucmerced.edu/wlai24/LapSRN/results/SR_testing_datasets.zip\n",
    "# !wget -P datasets/ http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-100/coil-100.zip\n",
    "# !wget -P datasets/ http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X2.zip\n",
    "# !wget -P datasets/ http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X2.zip\n",
    "# !wget -P datasets/ http://www.ponomarenko.info/tid2013/tid2013.rar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T08:50:26.291463Z",
     "start_time": "2020-06-08T08:50:26.122445Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.augmentations import get_aug\n",
    "from src.utils import walk_files\n",
    "from src.datasets import *\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T08:53:13.529231Z",
     "start_time": "2020-06-08T08:50:31.586592Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c99e75bb6d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTASK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repoz/metrics-comparison/src/augmentations.py\u001b[0m in \u001b[0;36mget_aug\u001b[0;34m(aug_type, task, dataset, size)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Add the same noise for all channels for single-channel images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMEAN_STD_BY_NAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"medicaldecathlon\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0msinglechannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "TASK = \"denoise\"\n",
    "SIZE = 256\n",
    "\n",
    "dataset_class = {\n",
    "    \"mnist\": MNIST,\n",
    "    \"fashion_mnist\": FashionMNIST, \n",
    "    \"cifar10\": CIFAR10,\n",
    "    \"cifar100\": CIFAR100,\n",
    "    \"tinyimagenet\": TinyImageNet,\n",
    "    \"div2k\": DIV2K,\n",
    "    \"set5\": Set5,\n",
    "    \"set14\": Set14,\n",
    "    \"urba100\": Urban100,\n",
    "    \"manga109\": Manga109,\n",
    "    \"coil100\": COIL100,\n",
    "    \"bsds100\": BSDS100,\n",
    "    \"medicaldecathlon\": MedicalDecathlon\n",
    "}\n",
    "\n",
    "\n",
    "dataset_names = [\n",
    "    \"div2k\",\n",
    "    \"bsds100\",\n",
    "#     \"set5\"\n",
    "]\n",
    "\n",
    "datasets = []\n",
    "for dataset_name in dataset_names:\n",
    "    transform = get_aug(aug_type=\"medium\", task=TASK, dataset=datasets, size=SIZE)\n",
    "    datasets.append(dataset_class[dataset_name](train=True, transform=transform))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    input, target = dataset[1]\n",
    "    print(\"Input\", input.shape, input.min(), input.max(), input.mean())\n",
    "    print(\"Target\", target.shape, target.min(), target.max(), target.mean())\n",
    "    plt.figure(figsize=(10, 15))\n",
    "    plt.imshow(torch.cat([input, target], dim=2).permute(1, 2, 0) * 0.5 + 0.5, )\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:03:51.120720Z",
     "start_time": "2020-05-29T13:03:51.118706Z"
    }
   },
   "outputs": [],
   "source": [
    "# total_mean, total_var = [], []\n",
    "# for i in range(len(div2k)):\n",
    "#     image = div2k[i][1]\n",
    "#     total_mean.append(image.mean(dim=[1,2]))\n",
    "#     total_var.append(image.var(dim=[1,2]))\n",
    "# print(torch.stack(total_mean).mean(dim=0))\n",
    "# print(torch.stack(total_var).mean(dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T15:59:56.557719Z",
     "start_time": "2020-05-29T15:59:55.444859Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T12:28:43.539258Z",
     "start_time": "2020-05-29T12:28:28.385984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset with no transform\n",
    "# AUG = get_aug(aug_type='light', dataset=\"medicaldecathlon\", task=\"denoise\", size=256)\n",
    "\n",
    "# medicaldecathlon = MedicalDecathlon(train=False, transform=AUG)\n",
    "# image = medicaldecathlon[135][0]\n",
    "# image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T14:59:14.735977Z",
     "start_time": "2020-04-26T14:58:51.307570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset with no transform\n",
    "# AUG = get_aug(aug_type='light', dataset=\"medicaldecathlon\", task=\"deblur\", size=256)\n",
    "\n",
    "# medicaldecathlon = MedicalDecathlon(train=False, transform=AUG)\n",
    "# image = medicaldecathlon[135][0]\n",
    "# image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:00:22.313189Z",
     "start_time": "2020-04-26T15:00:22.300261Z"
    }
   },
   "outputs": [],
   "source": [
    "print(image.min(), image.max(), image.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:46:02.588910Z",
     "start_time": "2020-04-26T10:46:02.235819Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx = 356\n",
    "print(image[..., 0].min(), image[..., 0].max(), image[...,0].mean())\n",
    "# plt.hist()\n",
    "# print(image.min(), image.max(), image.mean())\n",
    "# grey_image = image[..., 0]\n",
    "augmented = AUG(image=image, mask=image)\n",
    "input, target = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "## Get gaussian\n",
    "# random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n",
    "# gauss = random_state.normal(0, 0.1, input.shape)\n",
    "# input = input + gauss\n",
    "# gauss\n",
    "\n",
    "# print(\"Input\", input.shape, input.min(), input.max())\n",
    "# print(\"Target\", target.shape, target.min(), target.max())\n",
    "\n",
    "# augmented = NORM_TO_TENSOR(image=input, mask=target)\n",
    "# input, target = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "print(\"Input\", input.shape, input.min(), input.max())\n",
    "print(\"Target\", target.shape, target.min(), target.max())\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(torch.cat([input[0], target[0]], dim=1)) #.permute(1, 2, 0))\n",
    "# plt.imshow(torch.cat([input, target], dim=2).permute(1, 2, 0))\n",
    "\n",
    "torch.sum(input - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:46:15.660432Z",
     "start_time": "2020-04-26T10:46:15.622703Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.mean(input - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T10:12:01.132632Z",
     "start_time": "2020-04-25T10:12:01.115628Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow((medicaldecathlon[idx][0][..., 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T21:31:31.339877Z",
     "start_time": "2020-04-24T21:31:31.334100Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(256, 256)\n",
    "a = a[:,:,np.newaxis].repeat(3, axis=2)\n",
    "# a.repeat(3, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T21:04:44.034846Z",
     "start_time": "2020-04-24T21:04:43.900165Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(torch.cat([input, target], dim=2).permute(1, 2, 0)[:, :, [2, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T16:00:05.101620Z",
     "start_time": "2020-05-29T16:00:05.098635Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.datasets import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T16:18:18.394762Z",
     "start_time": "2020-05-29T16:18:10.979470Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [\"div2k\", \"bsds100\", \"set5\"]\n",
    "transform = get_aug(aug_type=\"val\", task=\"deblur\", size=128)\n",
    "\n",
    "for dataset in datasets:\n",
    "#     train_loader = get_dataloader(dataset, transform, train=True, batch_size=64)\n",
    "    \n",
    "#     for batch in train_loader:\n",
    "#         input, output = batch\n",
    "#         print(input.shape, output.shape)\n",
    "        \n",
    "    \n",
    "    val_loader = get_dataloader(dataset, transform, train=False)\n",
    "    for batch in val_loader:\n",
    "        input, output = batch\n",
    "        print(input.shape, output.shape)\n",
    "    \n",
    "    \n",
    "    for batch in train_loader:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T16:14:07.954107Z",
     "start_time": "2020-05-29T16:14:07.942725Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = BSDS100(\"datasets/BSDS100\", train=True, transform=transform)\n",
    "dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T18:52:16.029947Z",
     "start_time": "2020-04-14T18:52:16.024488Z"
    }
   },
   "outputs": [],
   "source": [
    "import photosynthesis_metrics as pm\n",
    "image_metrics = [\"kid\", {}, \"ssim\", {}, ]\n",
    "\n",
    "METRIC_FROM_NAME = {\n",
    "    \"ssim\" : pm.SSIMLoss,\n",
    "    \"ms-ssim\" : pm.MultiScaleSSIMLoss,\n",
    "    \"msid\" : pm.MSID,\n",
    "    \"fid\" : pm.FID,\n",
    "    \"kid\" : pm.KID,\n",
    "#     \"content\" : ContentLoss,\n",
    "#     \"style\" : StyleLoss,\n",
    "    \"tv\" : pm.TVLoss,\n",
    "}\n",
    "\n",
    "\n",
    "# for metric in image_metrics:\n",
    "image_metrics = [METRIC_FROM_NAME[metric](**kwargs) for metric, kwargs in zip(image_metrics[::2], image_metrics[1::2])]\n",
    "# list(zip(image_metrics[::2], image_metrics[1::2]))\n",
    "image_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T19:29:09.787795Z",
     "start_time": "2020-04-14T19:29:09.783997Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "output = OrderedDict({\n",
    "    'loss': 1,\n",
    "#     'mse': mse,\n",
    "#     'psnr': psnr,\n",
    "#     'ssim': ssim_score,\n",
    "#     # 'val_ms_ssim': ms_ssim_score,\n",
    "#     'input_features': input_features,\n",
    "#     'target_features': target_features\n",
    "})\n",
    "output[\"test\"] = 3\n",
    "output[\"foo\"] = \"bar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:08:23.644634Z",
     "start_time": "2020-04-26T15:08:23.508619Z"
    }
   },
   "outputs": [],
   "source": [
    "images = torch.rand((512, 2, 32, 32))\n",
    "target = torch.rand((512, 2, 64, 64))\n",
    "print(f\"Before interpolation: images {images.shape}\")\n",
    "images = F.interpolate(images, size=target.shape[-2:], mode=\"bilinear\")\n",
    "print(f\"After interpolation: images {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import b\n",
    "# \n",
    "iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:36:25.754041Z",
     "start_time": "2020-04-14T20:36:25.750728Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [\"foo\", \"bar\"]\n",
    "if \"foo\" in a:\n",
    "    print(a.index(\"foo\"))\n",
    "# a.append(\"loss\")\n",
    "# print(a)\n",
    "# a.pop()\n",
    "# a\n",
    "# for i in \"etc\", a:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:45:36.482862Z",
     "start_time": "2020-04-14T16:45:34.767973Z"
    }
   },
   "outputs": [],
   "source": [
    "features = make_layers(\n",
    "    [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"], \n",
    "    batch_norm=True\n",
    ")\n",
    "vgg_16 = VGG(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:45:37.757692Z",
     "start_time": "2020-04-14T16:45:37.751504Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:47:10.728420Z",
     "start_time": "2020-04-14T16:47:09.880830Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.rand(10, 3, 224, 224)\n",
    "layers = None\n",
    "if layers is None:\n",
    "    layers = [\"0\", \"5\", \"10\", \"19\", \"28\"]\n",
    "\n",
    "features = []\n",
    "for name, module in vgg_16.features._modules.items():\n",
    "    x = module(x)\n",
    "    if name in layers:\n",
    "        features.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:47:17.479314Z",
     "start_time": "2020-04-14T16:47:17.414244Z"
    }
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T14:30:14.494629Z",
     "start_time": "2020-04-14T14:30:14.490716Z"
    }
   },
   "outputs": [],
   "source": [
    "# from albumentations import ImageOnlyTransform\n",
    "albu.ImageCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T13:26:20.318480Z",
     "start_time": "2020-04-14T13:26:20.314695Z"
    }
   },
   "outputs": [],
   "source": [
    "target.permute(2, 0, 1).shape, input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T13:26:30.322997Z",
     "start_time": "2020-04-14T13:26:30.167211Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(target.permute(2, 0, 1).transpose(0, 2).transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:18:02.700784Z",
     "start_time": "2020-04-14T11:18:02.475697Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TinyImageNetDataset(train=True, transform=None, target_transform=None)\n",
    "input, target = dataset[6]\n",
    "# input.shape\n",
    "# plt.imshow(input / 255.)\n",
    "(input / 255.).min(), (input / 255.).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:09:29.108056Z",
     "start_time": "2020-04-14T11:09:29.104053Z"
    }
   },
   "outputs": [],
   "source": [
    "input.transpose(0, 2).transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:02:42.360140Z",
     "start_time": "2020-04-14T11:02:42.355048Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:13.348128Z",
     "start_time": "2020-04-09T10:52:13.337949Z"
    }
   },
   "outputs": [],
   "source": [
    "# from src.augmentations import get_aug\n",
    "# from src.datasets import MNIST, CIFAR10, CIFAR100\n",
    "from ..src.datasets\n",
    "# from src.datasets import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:11.714091Z",
     "start_time": "2020-04-08T14:27:11.660050Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = get_aug(aug_type=\"light\", size=32)\n",
    "target_transform = get_aug(aug_type=\"val\", size=32)\n",
    "# target_transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:12.035620Z",
     "start_time": "2020-04-08T14:27:11.981391Z"
    }
   },
   "outputs": [],
   "source": [
    "transform, target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:13.384001Z",
     "start_time": "2020-04-08T14:27:12.625838Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = CIFAR10(root='../datasets', train=True, transform=transform, target_transform=target_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# valset = CIFAR10(root='../datasets', train=False, transform=transform, target_transform=target_transform)\n",
    "# valloader = torch.utils.data.DataLoader(valset, batch_size=16,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:13.589831Z",
     "start_time": "2020-04-08T14:27:13.534077Z"
    }
   },
   "outputs": [],
   "source": [
    "image, target = trainset[0]\n",
    "print(image.shape, target.shape)\n",
    "print(image.max(), image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:14.716283Z",
     "start_time": "2020-04-08T14:27:14.483971Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "input, target = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:16.860006Z",
     "start_time": "2020-04-08T14:27:16.789254Z"
    }
   },
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:09:04.837084Z",
     "start_time": "2020-04-08T15:09:04.439944Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "model.fc = Identity()\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:09:07.391805Z",
     "start_time": "2020-04-08T15:09:07.348692Z"
    }
   },
   "outputs": [],
   "source": [
    "mock = torch.rand((3, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:09:08.273261Z",
     "start_time": "2020-04-08T15:09:08.185666Z"
    }
   },
   "outputs": [],
   "source": [
    "result = model(mock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:15:02.858962Z",
     "start_time": "2020-04-08T15:15:02.810410Z"
    }
   },
   "outputs": [],
   "source": [
    "all_input_features = [result.detach() for _ in range(4)]\n",
    "print(len(all_input_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:16:17.105471Z",
     "start_time": "2020-04-08T15:16:17.056511Z"
    }
   },
   "outputs": [],
   "source": [
    "input_features = torch.cat(all_input_features, dim=0)\n",
    "input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:54:58.027998Z",
     "start_time": "2020-04-08T14:54:57.979447Z"
    }
   },
   "outputs": [],
   "source": [
    "input.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T17:29:33.595967Z",
     "start_time": "2020-04-24T17:29:33.564780Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:11:48.608920Z",
     "start_time": "2020-04-24T19:11:48.604678Z"
    }
   },
   "outputs": [],
   "source": [
    "datapath = \"datasets/decathlon/colon.h5\"\n",
    "with h5py.File(datapath, \"r\") as f:\n",
    "    for key in f.keys():\n",
    "        print(key)\n",
    "#     data_val = f['imgs_validation'][::10]\n",
    "#     data_test = f['imgs_testing'][::10]\n",
    "#     data = np.concatenate((data_val, data_test))\n",
    "#     print(data.shape)\n",
    "#     print(len(data))\n",
    "    \n",
    "\n",
    "# hf = \n",
    "# data_numpy = np.zeros(hf['imgs_train'].shape, dtype=numpy_type)\n",
    "# # hf['dataset_name'].read_direct(n1)\n",
    "# # hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:17:10.798726Z",
     "start_time": "2020-04-24T19:17:10.390446Z"
    }
   },
   "outputs": [],
   "source": [
    "data = hf['imgs_train'][5000]\n",
    "mask = hf['msks_train'][5000]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(data.squeeze(), cmap='gray')\n",
    "# plt.imshow(mask.squeeze(), alpha=0.1)\n",
    "# data.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:13:31.176828Z",
     "start_time": "2020-04-24T19:13:30.998749Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T17:43:43.812272Z",
     "start_time": "2020-04-24T17:43:43.677479Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T17:31:12.884247Z",
     "start_time": "2020-04-24T17:31:12.881134Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test photosynthesis.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:18:15.396978Z",
     "start_time": "2020-05-29T10:18:15.393537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import photosynthesis_metrics as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:18:25.723333Z",
     "start_time": "2020-05-29T10:18:25.716300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:08:21.227486Z",
     "start_time": "2020-05-12T10:08:19.111299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ON CPU\n",
    "fid = pm.FID()\n",
    "predicted = torch.rand(10000, 1000)#.to(\"cuda:0\")\n",
    "target = torch.rand(10000, 1000)#.to(\"cuda:0\")\n",
    "%timeit score = fid(predicted, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:08:04.922701Z",
     "start_time": "2020-05-12T10:07:52.529352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ON GPU\n",
    "fid = pm.FID()\n",
    "predicted = torch.rand(10000, 1000).to(\"cuda:0\")\n",
    "target = torch.rand(10000, 1000).to(\"cuda:0\")\n",
    "%timeit score = fid(predicted, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:34:28.966236Z",
     "start_time": "2020-05-12T14:34:28.897034Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predicted = torch.rand(10000, 1000)\n",
    "predicted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:03:45.645367Z",
     "start_time": "2020-05-12T16:03:45.550217Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch                                                                                                                                                \n",
    "import photosynthesis_metrics as pm                                                                                                                     \n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "mnist = MNIST(root=\"/home/zakirov/repoz/metrics-comparison/datasets\", train=True)\n",
    "mnist_data1 = mnist.data.reshape(-1, 784)[:10000]\n",
    "mnist_data2 = mnist.data.reshape(-1, 784)[10000:]\n",
    "\n",
    "fmnist = FashionMNIST(root=\"/home/zakirov/repoz/metrics-comparison/datasets\", train=True)\n",
    "fmnist_data1 = fmnist.data.reshape(-1, 784)[:10000]\n",
    "fmnist_data2 = fmnist.data.reshape(-1, 784)[10000:]\n",
    "\n",
    "gs = pm.GS(num_iters=10, sample_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:35:47.909954Z",
     "start_time": "2020-05-12T16:35:47.828163Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "work = ([\"A\", 5], [\"B\", 2], [\"C\", 1], [\"D\", 3])\n",
    "\n",
    "# def work_log(work_data):\n",
    "#     print(\" Process %s waiting %s seconds\" % (work_data[0], work_data[1]))\n",
    "#     time.sleep(int(work_data[1]))\n",
    "#     print(\" Process %s Finished.\" % work_data[0])\n",
    "#     return work_data[1]\n",
    "\n",
    "\n",
    "def work_log(work_log):\n",
    "    res = np.ones((10, ))\n",
    "#     print(\"Hi\")\n",
    "    return res\n",
    "\n",
    "\n",
    "p = Pool(2)\n",
    "res = p.map(work_log, work)\n",
    "np.vstack(res)#.shape\n",
    "# p = Pool(2)\n",
    "# res = p.imap_unordered(work_log, range(5))\n",
    "\n",
    "    \n",
    "# p = Pool(6)\n",
    "\n",
    "\n",
    "# rlts = np.zeros((num_iters, i_max))\n",
    "#     for i in range(num_iters):\n",
    "#         rlts[i, :] = rlt(X, sample_size, gamma, i_max)\n",
    "#     return rlts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:33:47.839734Z",
     "start_time": "2020-05-12T16:33:47.834897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnist_mnist = gs(mnist_data1, mnist_data2)  \n",
    "fmnist_fmnist = gs(fmnist_data1, fmnist_data2)  \n",
    "\n",
    "fmnist_mnist1 = gs(fmnist_data1, mnist_data2) \n",
    "fmnist_mnist2 = gs(mnist_data1, fmnist_data2)  \n",
    "\n",
    "print(mnist_mnist, fmnist_fmnist, fmnist_mnist1, fmnist_mnist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Inception score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:08:45.538764Z",
     "start_time": "2020-05-18T13:08:45.534123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(1)\n",
    "a, torch.mean(a), torch.var(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Compute IS for CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:06:57.805822Z",
     "start_time": "2020-05-13T16:06:57.802189Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import inception_v3                                                                                                                 \n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import photosynthesis_metrics as pm    \n",
    "from photosynthesis_metrics import IS\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:07:03.862241Z",
     "start_time": "2020-05-13T16:07:03.179834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
    "\n",
    "aug = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "cifar10 = CIFAR10(root=\"/home/zakirov/repoz/metrics-comparison/datasets\", train=True, transform=aug)\n",
    "cifar10\n",
    "loader = torch.utils.data.DataLoader(cifar10, batch_size=100, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:16:23.449739Z",
     "start_time": "2020-05-13T15:16:20.585333Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model = pm.feature_extractors.fid_inception.InceptionV3(\n",
    "#     resize_input=True, \n",
    "#     normalize_input=True,\n",
    "#     requires_grad=False,\n",
    "#     use_fid_inception=False,\n",
    "# )\n",
    "model = inception_v3(pretrained=True, transform_input=False).cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:25:03.381523Z",
     "start_time": "2020-05-13T15:22:28.016731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "i = 0\n",
    "# num_batches = 20\n",
    "with torch.no_grad():\n",
    "    up = torch.nn.Upsample(size=(299, 299), mode='bilinear')\n",
    "    for batch in tqdm(loader):\n",
    "        images, labels = batch\n",
    "#         images = images.permute(0, 3, 1, 2)\n",
    "        images = up(images)\n",
    "        output = model(images.cuda())\n",
    "        scores.append(output.detach().cpu())\n",
    "#         i += 1\n",
    "#         if i == num_batches:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:50:42.055707Z",
     "start_time": "2020-05-13T15:50:39.492818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cifar10_features = torch.cat(scores, dim=0)\n",
    "\n",
    "# # Now compute the mean kl-div\n",
    "# split_scores = []\n",
    "# preds = torch.nn.functional.softmax(cifar10_features).data.cpu().numpy()\n",
    "# N = len(preds)\n",
    "# splits = 10\n",
    "# for k in range(splits):\n",
    "#     part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "#     py = np.mean(part, axis=0)\n",
    "#     sc = []\n",
    "#     for i in range(part.shape[0]):\n",
    "#         pyx = part[i, :]\n",
    "#         sc.append(entropy(pyx, py))\n",
    "#     split_scores.append(np.exp(np.mean(sc)))\n",
    "\n",
    "# print(N, np.mean(split_scores), np.std(split_scores))\n",
    "inception_score = IS(num_splits=10, ret_var=True)\n",
    "inception_score(cifar10_features, cifar10_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:29:22.038692Z",
     "start_time": "2020-05-13T14:29:10.348604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "       \n",
    "#     # Shape (1 x 3 x 32 x 3)\n",
    "#     images = images.permute(0, 3, 1, 2)\n",
    "#     images = F.interpolate(images,\n",
    "#                   size=(299, 299),\n",
    "#                   mode='bilinear',\n",
    "#                   align_corners=False) \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "# for batch in tqdm(loader):\n",
    "#     images, labels = batch\n",
    "# #     print(images.shape, images.min(), images.max())\n",
    "#     # Shape (1 x 3 x 32 x 3)\n",
    "#     images = images.permute(0, 3, 1, 2)\n",
    "#     images = F.interpolate(images,\n",
    "#                   size=(299, 299),\n",
    "#                   mode='bilinear',\n",
    "#                   align_corners=False) \n",
    "#     output = model(image)\n",
    "#     scores.append(output)\n",
    "# # for i in tqdm(range(num_batches)):\n",
    "# #     images = cifar10.data[i * batch_size: (i+1) * batch_size]\n",
    "# #     # To tensor. Shape (N x 32 x 32 x 3)\n",
    "# #     image = torch.tensor(images)\n",
    "# # #     print(image.shape)\n",
    "# #     # Shape (1 x 3 x 32 x 3)\n",
    "# #     image = image.permute(0, 3, 1, 2) / 255.0\n",
    "# #     image = F.interpolate(image,\n",
    "# #                   size=(299, 299),\n",
    "# #                   mode='bilinear',\n",
    "# #                   align_corners=False)\n",
    "# #     output = model(image)\n",
    "# #     scores.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:29:03.482975Z",
     "start_time": "2020-05-18T13:29:03.480677Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:32:24.092185Z",
     "start_time": "2020-05-18T13:32:24.089148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Geometry score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:43:51.665311Z",
     "start_time": "2020-05-19T20:43:51.663129Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import photosynthesis_metrics as pm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:37:01.177723Z",
     "start_time": "2020-05-18T18:37:01.119361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs = pm.GS(num_iters=20)\n",
    "f1 = torch.rand(1000, 20)\n",
    "f2 = torch.rand(1000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:42:16.347469Z",
     "start_time": "2020-05-19T20:42:16.344075Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r\"\"\" This module implements Geometry Score (GS) in PyTorch.\n",
    "\n",
    "Implementation is inspired by Valentin Khrulkov's (@KhrulkovV) implementation:\n",
    "https://github.com/KhrulkovV/geometry-score\n",
    "\n",
    "See paper for details:\n",
    "https://arxiv.org/pdf/1802.02664.pdf\n",
    "\"\"\"\n",
    "from typing import Optional\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from photosynthesis_metrics.base import BaseFeatureMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:42:29.452932Z",
     "start_time": "2020-05-19T20:42:29.439071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gudhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:52:36.494968Z",
     "start_time": "2020-05-19T20:52:36.485851Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relative(intervals: np.ndarray, alpha_max: float, i_max: int = 100) -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    For a collection of intervals this functions computes\n",
    "    RLT by formulas (2) and (3) from the paper. This function will be typically called\n",
    "    on the output of the gudhi persistence_intervals_in_dimension function.\n",
    "\n",
    "    Args:\n",
    "      intervals: list of intervals e.g. [[0, 1], [0, 2], [0, np.inf]].\n",
    "      alpha_max: The maximal persistence value\n",
    "      i_max: Upper bound on the value of beta_1 to compute.\n",
    "\n",
    "    Returns:\n",
    "        rlt: Array of size (i_max, ) containing desired RLT.\n",
    "    \"\"\"\n",
    "\n",
    "    persistence_intervals = []\n",
    "    # If for some interval we have that it persisted up to np.inf\n",
    "    # we replace this point with alpha_max.\n",
    "    for interval in intervals:\n",
    "        if not np.isinf(interval[1]):\n",
    "            persistence_intervals.append(list(interval))\n",
    "        elif np.isinf(interval[1]):\n",
    "            persistence_intervals.append([interval[0], alpha_max])\n",
    "\n",
    "    # If there are no intervals in H1 then we always observed 0 holes.\n",
    "    if len(persistence_intervals) == 0:\n",
    "        rlt = np.zeros(i_max)\n",
    "        rlt[0] = 1.0\n",
    "        return rlt\n",
    "\n",
    "    persistence_intervals_ext = persistence_intervals + [[0, alpha_max]]\n",
    "    persistence_intervals_ext = np.array(persistence_intervals_ext)\n",
    "    persistence_intervals = np.array(persistence_intervals)\n",
    "\n",
    "    # Change in the value of beta_1 may happen only at the boundary points\n",
    "    # of the intervals\n",
    "    switch_points = np.sort(np.unique(persistence_intervals_ext.flatten()))\n",
    "    rlt = np.zeros(i_max)\n",
    "    for i in range(switch_points.shape[0] - 1):\n",
    "        midpoint = (switch_points[i] + switch_points[i + 1]) / 2\n",
    "        s = 0\n",
    "        for interval in persistence_intervals:\n",
    "            # Count how many intervals contain midpoint\n",
    "            if midpoint >= interval[0] and midpoint < interval[1]:\n",
    "                s = s + 1\n",
    "        if (s < i_max):\n",
    "            rlt[s] += (switch_points[i + 1] - switch_points[i])\n",
    "\n",
    "    return rlt / alpha_max\n",
    "\n",
    "\n",
    "def lmrk_table(W: np.ndarray, L: np.ndarray):\n",
    "    r\"\"\"Construct an input for the gudhi.WitnessComplex function.\n",
    "    Args:\n",
    "        W: Array of size w x d, containing witnesses\n",
    "        L: Array of size l x d, containing landmarks\n",
    "\n",
    "    Returns:\n",
    "        distances: 3D array of size w x l x 2. It satisfies the property that\n",
    "            distances[i, :, :] is [idx_i, dists_i], where dists_i are the sorted distances \n",
    "            from the i-th witness to each point in L and idx_i are the indices of the corresponding points\n",
    "            in L, e.g., D[i, :, :] = [[0, 0.1], [1, 0.2], [3, 0.3], [2, 0.4]]\n",
    "        max_dist: Maximal distance between W and L\n",
    "    \"\"\"\n",
    "    a = cdist(W, L)\n",
    "    max_dist = np.max(a)\n",
    "    idx = np.argsort(a)\n",
    "    b = a[np.arange(np.shape(a)[0])[:, np.newaxis], idx]\n",
    "    distances = np.dstack([idx, b])\n",
    "    return distances, max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:52:36.879412Z",
     "start_time": "2020-05-19T20:52:36.873966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def witness(X, sample_size: int = 64, gamma: Optional[float] = None):\n",
    "    \"\"\"Compute the persistence intervals for the dataset X using the witness complex.\n",
    "\n",
    "    Args:\n",
    "        X: Array of shape (N_samples, data_dim) representing the dataset.\n",
    "        sample_size: Number of landmarks to use on each iteration.\n",
    "        gamma: Parameter determining maximum persistence value. Default is `1.0 / 128 * N_imgs / 5000`\n",
    "\n",
    "    Returns\n",
    "        A list of persistence intervals and the maximal persistence value.\n",
    "    \"\"\"\n",
    "    # Install gudhi only if needed\n",
    "    try:\n",
    "        import gudhi\n",
    "    except ImportError as e:\n",
    "        import six\n",
    "        error = e.__class__(\n",
    "            \"You are likely missing your GUDHI installation, \"\n",
    "            \"you should visit http://gudhi.gforge.inria.fr/python/latest/installation.html \"\n",
    "            \"for further instructions.\\nIf you use conda, you can use\\nconda install -c conda-forge gudhi\"\n",
    "        )\n",
    "        six.raise_from(error, e)\n",
    "\n",
    "    N = X.shape[0]\n",
    "    if gamma is None:\n",
    "        gamma= 1.0 / 128 * N / 5000\n",
    "\n",
    "    # Randomly sample `sample_size` points from X\n",
    "    idx = np.random.choice(N, sample_size)\n",
    "    landmarks = X[idx]\n",
    "\n",
    "    distances, max_dist = lmrk_table(W=X, L=landmarks)\n",
    "    wc = gudhi.WitnessComplex(distances)\n",
    "    alpha_max = max_dist * gamma\n",
    "    st = wc.create_simplex_tree(max_alpha_square=alpha_max, limit_dimension=2)\n",
    "\n",
    "    # This seems to modify the st object\n",
    "    st.persistence(homology_coeff_field=2)\n",
    "    intervals = st.persistence_intervals_in_dimension(1)\n",
    "    return intervals, alpha_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:52:37.417902Z",
     "start_time": "2020-05-19T20:52:37.413518Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rlt(\n",
    "    idx: int, X: np.ndarray, sample_size: int = 64, gamma: Optional[float] = None, i_max: int = 100) -> np.ndarray:\n",
    "    \"\"\"Implements Algorithm 1 for one sample of landmarks.\n",
    " \n",
    "    Args:\n",
    "        idx : Used for multiprocessing.Pool to work correctly\n",
    "        X: Array of shape (N_samples, data_dim) representing the dataset.\n",
    "        sample_size: Number of landmarks to use on each iteration.\n",
    "        gamma: Parameter determining maximum persistence value. Default is `1.0 / 128 * N_imgs / 5000`\n",
    "        i_max: Upper bound on the value of beta_1 to compute.\n",
    "    \n",
    "    Returns:\n",
    "      An array of size (i_max, ) containing RLT(i, 1, X, L)\n",
    "        for randomly sampled landmarks.\n",
    "    \"\"\"\n",
    "    intervals, alpha_max = witness(X, sample_size=sample_size, gamma=gamma)\n",
    "    result = relative(intervals, alpha_max, i_max=i_max)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:52:39.832004Z",
     "start_time": "2020-05-19T20:52:39.826870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rlts(X: np.ndarray, \n",
    "    sample_size: int = 64, num_iters: int = 200, gamma: Optional[float] = None, i_max: int = 100) -> np.ndarray:\n",
    "    r\"\"\"Implements Algorithm 1 from the paper.\n",
    "\n",
    "    Args:\n",
    "        X: Array of shape (N_samples, data_dim) representing the dataset.\n",
    "        sample_size: Number of landmarks to use on each iteration.\n",
    "        num_iters: Number of iterations. \n",
    "        gamma: Parameter determining maximum persistence value. Default is `1.0 / 128 * N_imgs / 5000`\n",
    "        i_max: Upper bound on the value of beta_1 to compute.\n",
    "\n",
    "    Returns:\n",
    "        rlts: Array of size (num_iters, i_max) containing RLT(i, 1, X, L) for\n",
    "            `num_iters` collection of randomly sampled landmarks.\n",
    "    \"\"\"\n",
    "    sample_rlts = np.zeros((num_iters, i_max))\n",
    "    for i in range(num_iters):\n",
    "        sample_rlts[i, :] = rlt(idx=None, X=X, sample_size=sample_size, gamma=gamma, i_max=i_max)\n",
    "    return sample_rlts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T20:52:42.054173Z",
     "start_time": "2020-05-19T20:52:42.045533Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parallel_rlts(X: np.ndarray, sample_size: int = 64, num_iters: int = 200, \n",
    "                  gamma: Optional[float] = None, i_max: int = 100, num_workers=4) -> np.ndarray:\n",
    "    r\"\"\"Implements Algorithm 1 from the paper.\n",
    "    Uses multiprocessing.Pool to make computations fastes. \n",
    "\n",
    "    Args:\n",
    "        X: Array of shape (N_samples, data_dim) representing the dataset.\n",
    "        sample_size: Number of landmarks to use on each iteration.\n",
    "        num_iters: Number of iterations. \n",
    "        gamma: Parameter determining maximum persistence value. Default is `1.0 / 128 * N_imgs / 5000`\n",
    "        i_max: Upper bound on the value of beta_1 to compute.\n",
    "\n",
    "    Returns:\n",
    "        rlts: Array of size (num_iters, i_max) containing RLT(i, 1, X, L) for\n",
    "            `num_iters` collection of randomly sampled landmarks.\n",
    "    \"\"\"\n",
    "    partial_rlt = partial(rlt, X=X, sample_size=sample_size, gamma=gamma, i_max=i_max)\n",
    "\n",
    "    # Use 6 processes by default\n",
    "    p = Pool(num_workers)\n",
    "    pool_result = p.map(partial_rlt, range(num_iters))\n",
    "    rlts = np.vstack(pool_result)\n",
    "    return rlts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:29:07.053666Z",
     "start_time": "2020-05-19T21:29:07.030496Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GS(BaseFeatureMetric):\n",
    "    r\"\"\"Interface of Geometry Score.\n",
    "    It's computed for a whole set of data and can use features from encoder instead of images itself to decrease\n",
    "    computation cost. GS can compare two data distributions with different number of samples.\n",
    "    But dimensionalities should match, otherwise it won't be possible to correctly compute statistics.\n",
    "\n",
    "    Args:\n",
    "        predicted_features (torch.Tensor): Low-dimension representation of predicted image set. Shape (N_pred, encoder_dim)\n",
    "        target_features (torch.Tensor): Low-dimension representation of target image set. Shape (N_targ, encoder_dim)\n",
    "\n",
    "    Returns:\n",
    "        score (torch.Tensor): Scalar value of the distance between image sets.\n",
    "\n",
    "    References:\n",
    "        .. [1] Khrulkov V., Oseledets I. (2018).\n",
    "        Geometry score: A method for comparing generative adversarial networks.\n",
    "        arXiv preprint, 2018.\n",
    "        https://arxiv.org/abs/1802.02664\n",
    "    \"\"\"\n",
    "    def __init__(self, sample_size: int = 64, num_iters: int = 10000, gamma: Optional[float] = None, \n",
    "                i_max: int = 100, num_workers: int = 4) -> None:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            sample_size: Number of landmarks to use on each iteration. \n",
    "                Higher values can give better accuracy, but increase computation cost.\n",
    "            num_iters: Number of iterations.  \n",
    "                Higher values can reduce variance, but increase computation cost.\n",
    "            gamma: Parameter determining maximum persistence value. Default is `1.0 / 128 * N_imgs / 5000`\n",
    "            i_max: Upper bound on i in RLT(i, 1, X, L)\n",
    "            num_workers: Number of proccess used for GS computation.\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.sample_size = sample_size\n",
    "        self.num_iters = num_iters\n",
    "        self.gamma = gamma\n",
    "        self.i_max = i_max\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def compute_metric(self, predicted_features: torch.Tensor, target_features: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"Implements Algorithm 2 from the paper.\n",
    "\n",
    "        Args:\n",
    "            predicted_features: Samples from data distribution.\n",
    "                Shape (N_samples, data_dim).\n",
    "            target_features: Samples from data distribution.\n",
    "                Shape (N_samples, data_dim).\n",
    "\n",
    "        Returns:\n",
    "            score: Scalar value of the distance between distributions.\n",
    "        \"\"\"\n",
    "\n",
    "        # GPU -> CPU -> Numpy (Currently only Numpy realization is supported)\n",
    "        rlt_predicted = parallel_rlts(\n",
    "            predicted_features.detach().cpu().numpy(), \n",
    "            sample_size=self.sample_size, \n",
    "            num_iters=self.num_iters,\n",
    "            gamma=None, \n",
    "            i_max=self.i_max,\n",
    "            num_workers=self.num_workers)\n",
    "        \n",
    "        rlt_target = parallel_rlts(\n",
    "            target_features.detach().cpu().numpy(), \n",
    "            sample_size=self.sample_size, \n",
    "            num_iters=self.num_iters,\n",
    "            gamma=None, \n",
    "            i_max=self.i_max,\n",
    "            num_workers=self.num_workers)\n",
    "\n",
    "        mean_rlt_predicted = np.mean(rlt_predicted, axis=0)\n",
    "        mean_rlt_target = np.mean(rlt_target, axis=0)\n",
    "\n",
    "        score = np.sum((mean_rlt_predicted - mean_rlt_target) ** 2)\n",
    " \n",
    "        return torch.tensor(score, device=predicted_features.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:29:44.516610Z",
     "start_time": "2020-05-19T21:29:44.511779Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs = GS(sample_size=64, num_iters=500, i_max=100, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:30:11.373963Z",
     "start_time": "2020-05-19T21:29:47.110976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1 = torch.randn(1000, 20)\n",
    "f2 = torch.randn(1000, 20)\n",
    "b1 = torch.distributions.Beta(2, 2).sample((1000, 20))\n",
    "gs(f1, f2) * 1000, gs(f1, b1) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:00:39.109083Z",
     "start_time": "2020-05-19T21:00:29.188234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1 = torch.randn(1000, 20)\n",
    "f2 = torch.randn(1000, 20)\n",
    "b1 = torch.distributions.Beta(2, 2).sample((1000, 20))\n",
    "gs(f1, f2) * 1000, gs(f1, b1) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:00:10.074264Z",
     "start_time": "2020-05-19T20:59:57.824671Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1 = torch.randn(1000, 20)\n",
    "f2 = torch.randn(1000, 20)\n",
    "b1 = torch.distributions.Beta(2, 2).sample((1000, 20))\n",
    "gs(f1, f2) * 1000, gs(f1, b1) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:22:15.649984Z",
     "start_time": "2020-05-19T21:22:15.644455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T21:24:15.699590Z",
     "start_time": "2020-05-19T21:24:15.536960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "sample_size = 128\n",
    "gamma = 1.0 / 128 * N / 5000\n",
    "idx = np.random.choice(N, sample_size)\n",
    "X = torch.randn(1000, 20)\n",
    "landmarks = X[idx]\n",
    "\n",
    "a = cdist(X, landmarks)\n",
    "max_dist = np.max(a)\n",
    "idx = np.argsort(a)\n",
    "b = a[np.arange(np.shape(a)[0])[:, np.newaxis], idx]\n",
    "distances = np.dstack([idx, b])\n",
    "\n",
    "wc = gudhi.WitnessComplex(distances)\n",
    "alpha_max = max_dist * gamma\n",
    "st = wc.create_simplex_tree(max_alpha_square=alpha_max, limit_dimension=2)\n",
    "\n",
    "# This seems to modify the st object\n",
    "st.persistence(homology_coeff_field=2)\n",
    "intervals = st.persistence_intervals_in_dimension(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lmrk_table(W: np.ndarray, L: np.ndarray):\n",
    "    r\"\"\"Construct an input for the gudhi.WitnessComplex function.\n",
    "    Args:\n",
    "        W: Array of size w x d, containing witnesses\n",
    "        L: Array of size l x d, containing landmarks\n",
    "\n",
    "    Returns:\n",
    "        distances: 3D array of size w x l x 2. It satisfies the property that\n",
    "            distances[i, :, :] is [idx_i, dists_i], where dists_i are the sorted distances \n",
    "            from the i-th witness to each point in L and idx_i are the indices of the corresponding points\n",
    "            in L, e.g., D[i, :, :] = [[0, 0.1], [1, 0.2], [3, 0.3], [2, 0.4]]\n",
    "        max_dist: Maximal distance between W and L\n",
    "    \"\"\"\n",
    "    a = cdist(W, L)\n",
    "    max_dist = np.max(a)\n",
    "    idx = np.argsort(a)\n",
    "    b = a[np.arange(np.shape(a)[0])[:, np.newaxis], idx]\n",
    "    distances = np.dstack([idx, b])\n",
    "    return distances, max_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# VIF (debug and compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:39:19.241373Z",
     "start_time": "2020-05-20T14:39:19.235588Z"
    },
    "hidden": true
   },
   "source": [
    "A computationally simpler, multi-scale pixel domain implementation whose performance is slightly worse than the Wavelet domain version presented in [2] can also be downloaded here . The pixel domain version also uses a scalar Random Field model for natural images, instead of a vector version in [2]. There are advantages to using the VIF in the pixel domain as well as some disadvantages. The principle advantage is computational simplicity. Secondly, the Wavelet transform used in [2] is a highly overcomplete decomposition that adds a lot of linear correlation between coefficients. While the wavelet decomposition allows scale-space-orientation analysis, this makes the assumptions of conditional independence in [2] weaker. Pixel domain methods avoid this weakness of assumption, but do not allow orientation analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:58:01.799888Z",
     "start_time": "2020-05-22T15:58:01.329111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import multivariate_normal\n",
    "from photosynthesis_metrics.utils import _adjust_dimensions, _validate_input\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from src.augmentations import get_aug\n",
    "from src.datasets import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:30:25.723226Z",
     "start_time": "2020-05-21T10:30:25.698263Z"
    },
    "code_folding": [
     1,
     18
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# PyTorch code\n",
    "def _gaussian_kernel2d(kernel_size: int = 5, sigma: float = 2.0) -> torch.Tensor:\n",
    "    r\"\"\"Returns 2D Gaussian kernel N(0,`sigma`)\n",
    "    Args:\n",
    "        kernel_size: Size\n",
    "        sigma: Sigma\n",
    "    Returns:\n",
    "        gaussian_kernel: 2D kernel with shape (kernel_size x kernel_size)\n",
    "        \n",
    "    \"\"\"\n",
    "    x = torch.arange(- (kernel_size // 2), kernel_size // 2 + 1).resize(1, kernel_size)\n",
    "    y = torch.arange(- (kernel_size // 2), kernel_size // 2 + 1).resize(kernel_size, 1)\n",
    "    kernel = torch.exp(-(x * x + y * y) / (2.0 * sigma ** 2))\n",
    "    # Normalize\n",
    "    kernel = kernel / torch.sum(kernel)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def vif_p(prediction: torch.Tensor, target: torch.Tensor,\n",
    "          sigma_n_sq: float = 2.0, data_range: int =1.0) -> torch.Tensor:\n",
    "    r\"\"\"Compute Visiual Information Fidelity in **pixel** domain for a batch of images.\n",
    "    This metric isn't symmetric, so make sure to place arguments in correct order.\n",
    "    Both inputs supposed to be in range [0, 1] with RGB order.\n",
    "    \n",
    "    Args:\n",
    "        prediction: Batch of predicted images with shape (batch_size x channels x H x W)\n",
    "        target: Batch of target images with shape  (batch_size x channels x H x W)\n",
    "        sigma_n_sq: HVS model parameter (variance of the visual noise).\n",
    "        data_range: Value range of input images (usually 1.0 or 255). Default: 1.0\n",
    "        \n",
    "    Note:\n",
    "        In original paper this method was used for bands in discrete wavelet decomposition.\n",
    "        Later on authors released code to compute VIF approximation in pixel domain.\n",
    "        See https://live.ece.utexas.edu/research/Quality/VIF.htm for details.\n",
    "        \n",
    "    \"\"\"\n",
    "    if data_range == 255:\n",
    "        prediction = prediction / 255.\n",
    "        target = target / 255.\n",
    "\n",
    "    # Check min image size!!!\n",
    "#     assert (prediction.size(-1) % 16 == 0) and (prediction.size(-1) % 16 == 0), \\\n",
    "#         f\"Inputs should be devisible by 16 in both spatial dimensions. Got shape {prediction.shape[-2:]}\"\n",
    "    \n",
    "    num_channels = prediction.size(1)\n",
    "    \n",
    "    # Convert RGB image to YCbCr and take luminance: Y = 0.299 R + 0.587 G + 0.114 B \n",
    "    if num_channels == 3:\n",
    "        prediction = 0.299 * prediction[:, 0, :, :] + \\\n",
    "                          0.587 * prediction[:, 1, :, :] + \\\n",
    "                          0.114 * prediction[:, 2, :, :]\n",
    "        # Add channel dimension\n",
    "        prediction = prediction[:, None, :, :]\n",
    "        \n",
    "        target = 0.299 * target[:, 0, :, :] + \\\n",
    "                      0.587 * target[:, 1, :, :] + \\\n",
    "                      0.114 * target[:, 2, :, :]   \n",
    "        # Add channel dimension\n",
    "        target = target[:, None, :, :]\n",
    "    \n",
    "    # Constant for numerical stability\n",
    "    EPS = 1e-10\n",
    "    prediction_vif, target_vif = 0, 0\n",
    "    \n",
    "    # Progressively downsample images and compute VIF on different scales\n",
    "    for scale in range(1, 5):\n",
    "        kernel_size = 2 ** (5 - scale) + 1\n",
    "        kernel = _gaussian_kernel2d(kernel_size, sigma=kernel_size / 5)\n",
    "        kernel = kernel.view(1, 1, kernel_size, kernel_size).to(prediction)\n",
    "\n",
    "        if scale > 1:\n",
    "            # Convolve and downsample\n",
    "            prediction = F.conv2d(prediction, kernel)[:, :, ::2, ::2]  # valid padding\n",
    "            target = F.conv2d(target, kernel)[:, :, ::2, ::2]  # valid padding\n",
    "\n",
    "        mu_trgt, mu_pred = F.conv2d(target, kernel), F.conv2d(prediction, kernel)  # valid padding\n",
    "        mu_trgt_sq, mu_pred_sq, mu_trgt_pred = mu_trgt * mu_trgt, mu_pred * mu_pred, mu_trgt * mu_pred\n",
    "\n",
    "        sigma_trgt_sq = F.conv2d(target ** 2, kernel) - mu_trgt_sq\n",
    "        sigma_pred_sq = F.conv2d(prediction ** 2, kernel) - mu_pred_sq\n",
    "        sigma_trgt_pred = F.conv2d(target * prediction, kernel) - mu_trgt_pred\n",
    "        \n",
    "        # Zero small negative values\n",
    "        sigma_trgt_sq[sigma_trgt_sq < 0] = 0\n",
    "        sigma_pred_sq[sigma_pred_sq < 0] = 0\n",
    "        \n",
    "        g = sigma_trgt_pred / (sigma_trgt_sq + EPS)\n",
    "        sigma_v_sq = sigma_pred_sq - g * sigma_trgt_pred\n",
    "\n",
    "        prediction_vif += torch.sum(torch.log10(1.0 + (g ** 2.) * sigma_trgt_sq / (sigma_v_sq + sigma_n_sq)), dim=[1,2,3])\n",
    "        target_vif += torch.sum(torch.log10(1.0 + sigma_trgt_sq / sigma_n_sq), dim=[1,2,3])\n",
    "\n",
    "    return prediction_vif / target_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Read 2 images used in acticle and compute score for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:32:58.164860Z",
     "start_time": "2020-05-21T10:32:58.138527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "fname1 = \"goldhill.gif\"\n",
    "# fname2 = \"goldhill_blur.gif\"\n",
    "# fname2 = \"goldhill_cs.gif\"\n",
    "fname2 = \"goldhill_jpeg.gif\"\n",
    "GT = torch.from_numpy(imageio.mimread(fname1)[0])\n",
    "P = torch.from_numpy(imageio.mimread(fname2)[0])\n",
    "# plt.imshow(GT)\n",
    "# plt.show()\n",
    "# plt.imshow(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:33:00.030595Z",
     "start_time": "2020-05-21T10:32:59.153828Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P_rgb = (P[None, None, :, :].repeat(1, 3, 1, 1) / 255.).requires_grad_(True)\n",
    "GT_rgb = (GT[None, None, :, :].repeat(1, 3, 1, 1) / 255.).requires_grad_(True)\n",
    "\n",
    "vif_pt = vif_p(P_rgb, GT_rgb, data_range=1.0)\n",
    "vif_pt.backward()\n",
    "print(vif_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:22:37.885142Z",
     "start_time": "2020-05-21T10:22:37.865854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vif_np, vif_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:17:00.077416Z",
     "start_time": "2020-05-21T10:17:00.059250Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sum(np.abs(vif_np[2] - vif_pt[2].squeeze().numpy()))\n",
    "# sum(abs(vif_np[0] - vif_pt[0].squeeze().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:01:08.017562Z",
     "start_time": "2020-05-21T10:01:07.982739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T13:56:58.494183Z",
     "start_time": "2020-05-20T13:56:58.093684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = get_aug(aug_type='light', task='deblur', size=64)\n",
    "\n",
    "loader = get_dataloader(\n",
    "    datasets=['tinyimagenet'],\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "for batch in loader:\n",
    "    break\n",
    "    \n",
    "lr = batch[0][1]\n",
    "hr = batch[1][1]\n",
    "print(lr.min(), lr.max())\n",
    "plt.imshow((lr.permute(1,2,0) + 1) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T13:56:58.642647Z",
     "start_time": "2020-05-20T13:56:58.513642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow((hr.permute(1,2,0) + 1) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T13:56:58.821542Z",
     "start_time": "2020-05-20T13:56:58.786768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vif = VIF()\n",
    "\n",
    "vif(batch[0], batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T13:46:39.197135Z",
     "start_time": "2020-05-20T13:46:39.081810Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Geometry score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T13:11:27.512723Z",
     "start_time": "2020-05-21T13:11:27.499750Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T15:00:40.660064Z",
     "start_time": "2020-05-21T15:00:40.647164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relative_numpy(intervals: np.ndarray, alpha_max: float, i_max: int = 100) -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    For a collection of intervals this functions computes\n",
    "    RLT by formulas (2) and (3) from the paper. This function will be typically called\n",
    "    on the output of the gudhi persistence_intervals_in_dimension function.\n",
    "\n",
    "    Args:\n",
    "      intervals: list of intervals e.g. [[0, 1], [0, 2], [0, np.inf]].\n",
    "      alpha_max: The maximal persistence value\n",
    "      i_max: Upper bound on the value of beta_1 to compute.\n",
    "\n",
    "    Returns:\n",
    "        rlt: Array of size (i_max, ) containing desired RLT.\n",
    "    \"\"\"\n",
    "\n",
    "    persistence_intervals = []\n",
    "    # If for some interval we have that it persisted up to np.inf\n",
    "    # we replace this point with alpha_max.\n",
    "    for interval in intervals:\n",
    "        if not np.isinf(interval[1]):\n",
    "            persistence_intervals.append(list(interval))\n",
    "        elif np.isinf(interval[1]):\n",
    "            persistence_intervals.append([interval[0], alpha_max])\n",
    "\n",
    "    # If there are no intervals in H1 then we always observed 0 holes.\n",
    "    if len(persistence_intervals) == 0:\n",
    "        rlt = np.zeros(i_max)\n",
    "        rlt[0] = 1.0\n",
    "        return rlt\n",
    "\n",
    "    persistence_intervals_ext = persistence_intervals + [[0, alpha_max]]\n",
    "    persistence_intervals_ext = np.array(persistence_intervals_ext)\n",
    "    persistence_intervals = np.array(persistence_intervals)\n",
    "\n",
    "    # Change in the value of beta_1 may happen only at the boundary points\n",
    "    # of the intervals\n",
    "    switch_points = np.sort(np.unique(persistence_intervals_ext.flatten()))\n",
    "    rlt = np.zeros(i_max)\n",
    "    for i in range(switch_points.shape[0] - 1):\n",
    "        midpoint = (switch_points[i] + switch_points[i + 1]) / 2\n",
    "        s = 0\n",
    "        for interval in persistence_intervals:\n",
    "            # Count how many intervals contain midpoint\n",
    "            if midpoint >= interval[0] and midpoint < interval[1]:\n",
    "                s = s + 1\n",
    "        if (s < i_max):\n",
    "            rlt[s] += (switch_points[i + 1] - switch_points[i])\n",
    "\n",
    "    return rlt / alpha_max\n",
    "\n",
    "\n",
    "def relative_pytorch(intervals: torch.Tensor, alpha_max: float, i_max: int = 100) -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    For a collection of intervals this functions computes\n",
    "    RLT by formulas (2) and (3) from the paper. This function will be typically called\n",
    "    on the output of the gudhi persistence_intervals_in_dimension function.\n",
    "\n",
    "    Args:\n",
    "      intervals: list of intervals e.g. [[0, 1], [0, 2], [0, np.inf]].\n",
    "      alpha_max: The maximal persistence value\n",
    "      i_max: Upper bound on the value of beta_1 to compute.\n",
    "\n",
    "    Returns:\n",
    "        rlt: Array of size (i_max, ) containing desired RLT.\n",
    "    \"\"\"\n",
    "\n",
    "    persistence_intervals = []\n",
    "    # If for some interval we have that it persisted up to np.inf\n",
    "    # we replace this point with alpha_max.\n",
    "    for interval in intervals:\n",
    "        if torch.isinf(interval[1]):\n",
    "            persistence_intervals.append([interval[0], alpha_max])\n",
    "        else:\n",
    "            persistence_intervals.append(list(interval))\n",
    "\n",
    "    # If there are no intervals in H1 then we always observed 0 holes.\n",
    "    if len(persistence_intervals) == 0:\n",
    "        rlt = torch.zeros(i_max)\n",
    "        rlt[0] = 1.0\n",
    "        return rlt\n",
    "\n",
    "    persistence_intervals_ext = persistence_intervals + [[0, alpha_max]]\n",
    "    persistence_intervals_ext = torch.tensor(persistence_intervals_ext)\n",
    "    persistence_intervals = torch.tensor(persistence_intervals)\n",
    "\n",
    "    # Change in the value of beta_1 may happen only at the boundary points\n",
    "    # of the intervals\n",
    "    switch_points = torch.sort(torch.unique(persistence_intervals_ext.flatten()))\n",
    "    rlt = torch.zeros(i_max)\n",
    "    for i in range(switch_points.shape[0] - 1):\n",
    "        midpoint = (switch_points[i] + switch_points[i + 1]) / 2\n",
    "        s = 0\n",
    "        for interval in persistence_intervals:\n",
    "            # Count how many intervals contain midpoint\n",
    "            if midpoint >= interval[0] and midpoint < interval[1]:\n",
    "                s = s + 1\n",
    "        if (s < i_max):\n",
    "            rlt[s] += (switch_points[i + 1] - switch_points[i])\n",
    "\n",
    "    return rlt / alpha_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T15:46:42.228548Z",
     "start_time": "2020-05-21T15:46:42.224078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(10,10)\n",
    "torch.mean(a, axis=0) - a.mean(dim=0)\n",
    "\n",
    "# switch_points = torch.sort(torch.unique(persistence_intervals_ext.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T15:46:06.898875Z",
     "start_time": "2020-05-21T15:46:06.894009Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T15:27:31.724402Z",
     "start_time": "2020-05-21T15:27:31.719580Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# np.isinf(np.inf)\n",
    "torch.tensor(np.array([1., 3., float(\"Inf\"), 4]))\n",
    "# torch.tensor([1., 3., float(\"Inf\"), 4])[2]\n",
    "# torch.isinf(float(\"Inf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T15:01:45.191283Z",
     "start_time": "2020-05-21T15:01:45.183115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# res1[1].detach().cpu().numpy() - res2[1]\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T12:28:22.414794Z",
     "start_time": "2020-05-22T12:28:22.127390Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T12:54:46.757171Z",
     "start_time": "2020-05-22T12:54:46.731090Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def my_cdist(x1, x2):\n",
    "    x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "    res = torch.addmm(x2_norm.transpose(-2, -1), x1, x2.transpose(-2, -1), alpha=-2).add_(x1_norm)\n",
    "    res = res.clamp_min_(1e-30).sqrt_()\n",
    "    return res\n",
    "\n",
    "\n",
    "a = torch.randn(10000, 20, dtype=torch.float64)#.cuda()\n",
    "b = torch.randn(256, 20, dtype=torch.float64)#.cuda()\n",
    "\n",
    "a_n = np.random.randn(10000, 20)\n",
    "b_n = np.random.randn(256, 20)\n",
    "a.dtype, a_n.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T12:54:53.274247Z",
     "start_time": "2020-05-22T12:54:47.205024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit torch.cdist(a, b)\n",
    "\n",
    "%timeit my_cdist(a, b)\n",
    "\n",
    "%timeit cdist(a_n, b_n)\n",
    "# for i in range(5):\n",
    "#     start_time = time.time()\n",
    "#     res = torch.cdist(torch.tensor(a), torch.tensor(b)).numpy()\n",
    "#     res = torch.cdist(a, b)\n",
    "#     torch.cuda.synchronize()\n",
    "#     print(f'torch cdist time {i}: {time.time() - start_time:.2f}s')\n",
    "\n",
    "# for i in range(5):\n",
    "#     start_time = time.time()\n",
    "#     res2 = my_cdist(a, b)\n",
    "#     torch.cuda.synchronize()\n",
    "#     print(f'my cdist time {i}: {time.time() - start_time:.2f}s')\n",
    "    \n",
    "# for i in range(5):\n",
    "#     start_time = time.time()\n",
    "#     res3 = cdist(a_n, b_n)\n",
    "#     print(f'numpy cdist time {i}: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T13:46:46.800367Z",
     "start_time": "2020-05-20T13:46:46.744487Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Gradient Strength Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T13:06:47.609155Z",
     "start_time": "2020-05-28T13:06:47.301538Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T14:24:42.083652Z",
     "start_time": "2020-05-28T14:24:39.759374Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(\"P_rgb min/max: \", P_rgb.min(), P_rgb.max())\n",
    "gmsd = GMSDLoss(data_range=255)\n",
    "gmsd_from_ms_gmsd = MultiScaleGMSDLoss(data_range=255, chromatic=False, scale_weights=[0., 1., 0., 0.])\n",
    "ms_gmsd = MultiScaleGMSDLoss(data_range=255, chromatic=True)\n",
    "\n",
    "print(gmsd(P_rgb, GT_rgb))\n",
    "gmsd_from_ms_gmsd(P_rgb, GT_rgb)\n",
    "\n",
    "# %timeit ms_gmsd(P_rgb, GT_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T13:46:54.043822Z",
     "start_time": "2020-05-28T13:46:54.011918Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load test images\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "fname1 = \"goldhill.gif\"\n",
    "# fname2 = \"goldhill.gif\"\n",
    "# fname2 = \"goldhill_blur.gif\" # tensor(0.1746)\n",
    "fname2 = \"goldhill_cs.gif\"\n",
    "# fname2 = \"goldhill_jpeg.gif\" # tensor(0.3189)\n",
    "# fname2 = \"YIQ_components.jpg\"\n",
    "# fname2 = \"goldhill_jpeg.gif\"\n",
    "\n",
    "GT = torch.from_numpy(imageio.mimread(fname1)[0])\n",
    "P = torch.from_numpy(imageio.mimread(fname2)[0])\n",
    "\n",
    "\n",
    "P_rgb = (P[None, None, :, :].repeat(64, 3, 1, 1))#.requires_grad_(True)\n",
    "GT_rgb = (GT[None, None, :, :].repeat(64, 3, 1, 1))#.requires_grad_(True)\n",
    "\n",
    "# P_rgb = torch.ones(4, 3, 512, 512) #.requires_grad_(True)\n",
    "# GT_rgb = torch.zeros(4, 3, 512, 512) #.requires_grad_(True)\n",
    "\n",
    "# plt.imshow(GT)\n",
    "# plt.show()\n",
    "# plt.imshow(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Peceptual loss, Style loss, LPIPS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of VGG16 loss, originaly used for style transfer and usefull in many other task (including GAN training)\n",
    "It's work in progress, no guarantees that code will work\n",
    "\"\"\"\n",
    "import collections\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss \n",
    "from torchvision.models import vgg16\n",
    "\n",
    "\n",
    "\n",
    "def listify(p):\n",
    "    if p is None:\n",
    "        p = []\n",
    "    elif not isinstance(p, collections.Iterable):\n",
    "        p = [p]\n",
    "    return p\n",
    "\n",
    "class PSNR(_Loss):\n",
    "    def forward(self, prediction, target):\n",
    "        mse = torch.mean((prediction - target) ** 2)\n",
    "        psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "        return psnr\n",
    "\n",
    "\n",
    "\n",
    "class ContentLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Creates content loss for neural style transfer.\n",
    "    Uses pretrained VGG16 model from torchvision by default\n",
    "    layers: list of VGG layers used to evaluate content loss\n",
    "    criterion: str in ['mse', 'mae'], reduction method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers=[\"21\"],\n",
    "        weights=1,\n",
    "        loss=\"mse\",\n",
    "        device=\"cuda\",\n",
    "        **args,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = vgg16(pretrained=True, **args)\n",
    "        self.model.eval().to(device)\n",
    "        self.layers = listify(layers)\n",
    "        self.weights = listify(weights)\n",
    "\n",
    "        if loss == \"mse\":\n",
    "            self.criterion = nn.MSELoss()\n",
    "        elif loss == \"mae\":\n",
    "            self.criterion = nn.L1Loss()\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "    def forward(self, input, content):\n",
    "        \"\"\"\n",
    "        Measure distance between feature representations of input and content images\n",
    "        \"\"\"\n",
    "        input_features = torch.stack(self.get_features(input))\n",
    "        content_features = torch.stack(self.get_features(content))\n",
    "        loss = self.criterion(input_features, content_features)\n",
    "\n",
    "        # Solve big memory consumption\n",
    "        torch.cuda.empty_cache()\n",
    "        return loss\n",
    "\n",
    "    def get_features(self, x):\n",
    "        \"\"\"\n",
    "        Extract feature maps from the intermediate layers.\n",
    "        \"\"\"\n",
    "        if self.layers is None:\n",
    "            self.layers = [\"21\"]\n",
    "\n",
    "        features = []\n",
    "        for name, module in self.model.features._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.layers:\n",
    "                features.append(x)\n",
    "        # print(len(features))\n",
    "        return features\n",
    "\n",
    "\n",
    "class StyleLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Class for creating style loss for neural style transfer\n",
    "    model: str in ['vgg16_bn']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers=[\"0\", \"5\", \"10\", \"19\", \"28\"],\n",
    "        weights=[0.75, 0.5, 0.2, 0.2, 0.2],\n",
    "        loss=\"mse\",\n",
    "        device=\"cuda\",\n",
    "        **args,\n",
    "    ):\n",
    "        super().__init__() \n",
    "        self.model = vgg16(pretrained=True, **args)\n",
    "        self.model.eval().to(device)\n",
    "\n",
    "        self.layers = listify(layers)\n",
    "        self.weights = listify(weights)\n",
    "\n",
    "        if loss == \"mse\":\n",
    "            self.criterion = nn.MSELoss()\n",
    "        elif loss == \"mae\":\n",
    "            self.criterion = nn.L1Loss()\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "    def forward(self, input, style):\n",
    "        \"\"\"\n",
    "        Measure distance between feature representations of input and content images\n",
    "        \"\"\"\n",
    "        input_features = self.get_features(input)\n",
    "        style_features = self.get_features(style)\n",
    "        # print(style_features[0].size(), len(style_features))\n",
    "\n",
    "        input_gram = [self.gram_matrix(x) for x in input_features]\n",
    "        style_gram = [self.gram_matrix(x) for x in style_features]\n",
    "\n",
    "        loss = [\n",
    "            self.criterion(torch.stack(i_g), torch.stack(s_g)) for i_g, s_g in zip(input_gram, style_gram)\n",
    "        ]\n",
    "        return torch.mean(torch.tensor(loss))\n",
    "\n",
    "    def get_features(self, x):\n",
    "        \"\"\"\n",
    "        Extract feature maps from the intermediate layers.\n",
    "        \"\"\"\n",
    "        if self.layers is None:\n",
    "            self.layers = [\"0\", \"5\", \"10\", \"19\", \"28\"]\n",
    "\n",
    "        features = []\n",
    "        for name, module in self.model.features._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.layers:\n",
    "                features.append(x)\n",
    "        return features\n",
    "\n",
    "    def gram_matrix(self, input):\n",
    "        \"\"\"\n",
    "        Compute Gram matrix for each image in batch\n",
    "        input: Tensor of shape BxCxHxW\n",
    "            B: batch size\n",
    "            C: channels size\n",
    "            H&W: spatial size\n",
    "        \"\"\"\n",
    "\n",
    "        B, C, H, W = input.size()\n",
    "        gram = []\n",
    "        for i in range(B):\n",
    "            x = input[i].view(C, H * W)\n",
    "            gram.append(torch.mm(x, x.t()))\n",
    "        return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T10:51:49.575920Z",
     "start_time": "2020-05-23T10:51:49.572849Z"
    },
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
