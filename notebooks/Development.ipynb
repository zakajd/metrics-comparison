{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:01:18.075290Z",
     "start_time": "2020-06-08T19:01:17.002797Z"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import functools\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import albumentations as albu\n",
    "import albumentations.pytorch as albu_pt\n",
    "import photosynthesis_metrics as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:01:19.769751Z",
     "start_time": "2020-06-08T19:01:19.579605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 08 2020 \n",
      "\n",
      "CPython 3.6.9\n",
      "IPython 7.8.0\n",
      "\n",
      "numpy 1.17.0\n",
      "torch 1.5.0\n",
      "albumentations 0.4.5\n",
      "photosynthesis_metrics 0.3.0\n",
      "\n",
      "compiler   : GCC 8.4.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-99-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "# Fix to be able to import python modules inside a notebook\n",
    "os.chdir('..')\n",
    "\n",
    "# Useful extensions\n",
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,torch,albumentations,photosynthesis_metrics\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Nice plot formating\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TID2013 dataset\n",
    "\n",
    "1. Парные сравнения изображений с оригинальными версиями для попиксельных метрик\n",
    "2. Дробить на множество маленьких кусочков для distribution метрик\n",
    "3. Выдавать только distorted изображения для no-reference метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:01:22.054153Z",
     "start_time": "2020-06-08T19:01:22.037971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Task specific imports\n",
    "from src.utils import walk_files\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:01:23.558045Z",
     "start_time": "2020-06-08T19:01:23.545404Z"
    }
   },
   "outputs": [],
   "source": [
    "class TID2013(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Total length = 120 (3000 / 25)\n",
    "    Args:\n",
    "        root (str) – Root directory path.\n",
    "        train (bool): Flag to return train if True and validation if False\n",
    "        transform (callable) – A function/transform that takes in the input and transforms it.\n",
    "        \n",
    "    Returns:\n",
    "        distorted: 25 images with fixed distortion type and level\n",
    "        reference: 25 original images\n",
    "    \"\"\"\n",
    "    _filename = \"/mos_with_names.txt\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, root=\"data/raw/tid2013\", transform=None):\n",
    "        \n",
    "        reference_walker = walk_files(\n",
    "            root + \"/reference_images\", suffix=(\".bmp\", \".BMP\"), prefix=True, remove_suffix=False\n",
    "        )\n",
    "        self.reference_files = sorted(list(reference_walker))    \n",
    "    \n",
    "        # Read file mith MOS and names\n",
    "        with open(root + self._filename) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        scores, self.distorted_files = [], []\n",
    "        \n",
    "        for line in lines:\n",
    "            score, name = line.split(' ')\n",
    "            scores.append(float(score))\n",
    "            self.distorted_files.append(root + \"/distorted_images/\" + name[:-1])\n",
    "        \n",
    "        self.scores = np.array(scores)\n",
    "        \n",
    "        if transform is None:\n",
    "            self.transform = albu_pt.ToTensorV2()\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        step = int(len(self.distorted_files) / len(self.reference_files)) # 120\n",
    "        distorted_files = self.distorted_files[index::step]\n",
    "        assert len(distorted_files) == len(self.reference_files)\n",
    "        \n",
    "        distorted_images, reference_images = [], []\n",
    "        for i in range(len(distorted_files)):\n",
    "            # Load image and ref\n",
    "            distorted = imageio.imread(distorted_files[i])\n",
    "            distorted = self.transform(image=distorted)[\"image\"]\n",
    "            \n",
    "            reference = imageio.imread(self.reference_files[i])\n",
    "            reference = self.transform(image=reference)[\"image\"]\n",
    "        \n",
    "            distorted_images.append(distorted.unsqueeze(0))\n",
    "            reference_images.append(reference.unsqueeze(0))\n",
    "            \n",
    "        distorted_images = torch.cat(distorted_images, dim=0)\n",
    "        reference_images = torch.cat(reference_images, dim=0)\n",
    "\n",
    "        scores = self.scores[index::step]\n",
    "        return distorted_images, reference_images, scores\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.distorted_files) / len(self.reference_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:01:24.937975Z",
     "start_time": "2020-06-08T19:01:24.494092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "\n",
    "transform = albu.Compose([\n",
    "#     albu.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # to [-1, 1]\n",
    "    albu.Normalize(mean=[0., 0., 0.], std=[1., 1., 1.]), # to [0, 1]\n",
    "    albu_pt.ToTensorV2(),\n",
    "])\n",
    "\n",
    "dataset = TID2013(transform=transform)\n",
    "distorted_images, reference_images, scores = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on images and compute score\n",
    "\n",
    "1. Prediction in form 1, 121, 241, ...\n",
    "2. want to be 1, 2, 3, 4, 5, 6, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:01:40.726099Z",
     "start_time": "2020-06-08T19:01:40.721084Z"
    }
   },
   "outputs": [],
   "source": [
    "# MOS scores ordered by image name\n",
    "mos_path = \"data/raw/tid2013/mos.txt\"\n",
    "# Read file mith MOS\n",
    "with open(mos_path) as f:\n",
    "    mos_scores = f.readlines()\n",
    "mos_scores = [float(score) for score in mos_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:05:57.430227Z",
     "start_time": "2020-06-08T19:05:57.425493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0306, 0.0226, 0.4322, 0.7475]),\n",
       " tensor([0.8428, 0.0030, 0.8655, 0.2265]),\n",
       " tensor([0.4773, 0.7080, 0.8092, 0.9406])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [torch.rand(4), torch.rand(4), torch.rand(4)]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:08:15.479284Z",
     "start_time": "2020-06-08T19:08:15.470561Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4f21d6db76d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:09:26.716089Z",
     "start_time": "2020-06-08T19:09:26.711457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0306, 0.8428, 0.4773, 0.0226, 0.0030, 0.7080, 0.4322, 0.8655, 0.8092,\n",
       "        0.7475, 0.2265, 0.9406])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(r).t().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:11:47.797251Z",
     "start_time": "2020-06-08T19:10:59.078116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5641e4d294b4023815e94e629791efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Abstract iterator \n",
    "metric_scores = []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    distorted_images, reference_images, true_scores = dataset[0]\n",
    "#     predicted_scores = metric(distorted_images, reference_images)\n",
    "    predicted_scores = torch.tensor(true_scores)\n",
    "    metric_scores.append(predicted_scores)\n",
    "\n",
    "# Transpose to flatten in column-wise order\n",
    "metric_scores = torch.stack(metric_scores, dim=0).t().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_patches(images: torch.Tensor, size=64, stride=32):\n",
    "    \"\"\"Crop input images into smaller patches\n",
    "    Args:\n",
    "        images: Tensor of images with shape (batch x 3 x H x W)\n",
    "        size: size of a square patch\n",
    "        stride: Step between patches\n",
    "    \"\"\"\n",
    "    shape = images.shape\n",
    "    patches = images.data.unfold(1, 3, 3).unfold(2, size, stride).unfold(3, size, stride)\n",
    "    patches = patches.reshape(-1, 3, size, size)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:14:54.717747Z",
     "start_time": "2020-06-08T19:14:54.707926Z"
    }
   },
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = nn.Parameter(torch.ones(1))# * 1e-3)\n",
    "        self.b2 = nn.Parameter(torch.ones(1)) #* 1e-3)\n",
    "        self.b3 = nn.Parameter(torch.ones(1)) # * 1e-3)\n",
    "        self.b4 = nn.Parameter(torch.ones(1)) # * 1e-3)\n",
    "        self.b5 = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, predicted_scores):\n",
    "        adjusted = self.b1 * (0.5 - 1 / (1 + torch.exp(self.b2 * (predicted_scores - self.b3)))) + \\\n",
    "            predicted_scores * self.b4 + self.b5\n",
    "        return adjusted\n",
    "\n",
    "def pearson_correlation(x, y, invert=False):\n",
    "    vx = x - torch.mean(x)\n",
    "    vy = y - torch.mean(y)\n",
    "\n",
    "    corr = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    if invert: \n",
    "        return 1 - corr\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:14:55.947099Z",
     "start_time": "2020-06-08T19:14:55.936663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7586402890911867 tensor(0.7586)\n",
      "0.758640289091187\n",
      "0.9757575757575757\n",
      "0.911111111111111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "x = np.arange(10, 20)\n",
    "y = np.array([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "x_t = torch.tensor(x, dtype=torch.float32)\n",
    "y_t = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "r = np.corrcoef(x, y)[0, 1]\n",
    "r_t = pearson_correlation(x_t, y_t)\n",
    "print(r, r_t)\n",
    "\n",
    "print(scipy.stats.pearsonr(x, y)[0])    # Pearson's r\n",
    "\n",
    "print(scipy.stats.spearmanr(x, y)[0])   # Spearman's rho\n",
    "\n",
    "print(scipy.stats.kendalltau(x, y)[0])  # Kendall's tau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-08T19:14:56.665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNRHVSM (0): 1.0107723474502563\n",
      "NaN in loss!\n",
      "VIFP (0): 0.3845893144607544\n",
      "VIFP (5000): 0.24854415655136108\n",
      "VIFP (10000): 0.2481238842010498\n",
      "VIFP: PLCC 0.752, SRCC 0.658 KRCC 0.481\n",
      "MSSIM (0): 0.2195185422897339\n",
      "MSSIM (5000): 0.16958576440811157\n"
     ]
    }
   ],
   "source": [
    "# 1. Load MOS score\n",
    "# 2. Load score for FSIMc\n",
    "# 3. Fit regression using MSE loss\n",
    "# 4. Fit regression using PLCC loss\n",
    "# 5. Compute PLCC, SRCC in both cases\n",
    "# 6. Compare with values from the paper\n",
    "\n",
    "learningRate = 0.01\n",
    "epochs = 10000\n",
    "    \n",
    "metric_names = [\"PSNRHVSM\", \"VIFP\", \"MSSIM\", \n",
    "#                 \"WSNR\", \"PSNRHMA\", \"FSIM\", \"SSIM\", \"PSNRc\", \"PSNR\", \"FSIMc\", \n",
    "#                \"PSNRHVS\", \"PSNRHA\", \"VSNR\", \"NQM\"\n",
    "               ]\n",
    "\n",
    "\n",
    "for metric in metric_names:\n",
    "    done = False\n",
    "    metric_path = \"data/raw/tid2013/metrics_values/\" + metric + \".txt\"\n",
    "    # Read metric score\n",
    "    with open(metric_path) as f:\n",
    "        metric_scores = f.readlines()\n",
    "\n",
    "    metric_scores = [float(score) for score in metric_scores]\n",
    "\n",
    "    model = Regression()\n",
    "#     criterion = torch.nn.MSELoss() \n",
    "    criterion = functools.partial(pearson_correlation, invert=True)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=learningRate)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=100, cooldown=50)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=learningRate, max_lr=0.05)\n",
    "\n",
    "    prediction = torch.tensor(metric_scores)\n",
    "    target = torch.tensor(mos_scores)\n",
    "\n",
    "    # Fit regression\n",
    "    for epoch in range(epochs + 1):\n",
    "        if done:\n",
    "            continue\n",
    "        # Clear gradient \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(prediction)\n",
    "\n",
    "        # Get loss for the predicted output\n",
    "        loss = criterion(outputs, target)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN in loss!\")\n",
    "            done = True\n",
    "            continue\n",
    "            \n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        if epoch % 5000 == 0:\n",
    "            print(f'{metric} ({epoch}): {loss.item()}')\n",
    "    \n",
    "    if done:\n",
    "        continue\n",
    "    # Compute metrics:\n",
    "    x = outputs.detach().numpy()\n",
    "    y = mos_scores\n",
    "    print(f\"{metric}: PLCC {pearsonr(x, y)[0]:0.3f}, SRCC {spearmanr(x, y)[0]:0.3f}\", \n",
    "          f\"KRCC {kendalltau(x, y)[0]:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = \"\"\"VIFP: PLCC 0.752 SRCC 0.658 KRCC 0.481\n",
    "MSSIM PLCC 0.831 SRCC 0.787 KRCC 0.608\n",
    "PSNRHMA PLCC 0.799 SRCC 0.813 KRCC 0.632\n",
    "FSIM PLCC 0.854 SRCC 0.801 KRCC 0.630\n",
    "SSIM PLCC 0.684 SRCC 0.637 KRCC 0.464\n",
    "PSNRc PLCC 0.660 SRCC 0.687 KRCC 0.496\n",
    "FSIMc PLCC 0.870 SRCC 0.851 KRCC 0.667\n",
    "PSNRHA PLCC 0.796 SRCC 0.819 KRCC 0.643\"\"\"\n",
    "result = {}\n",
    "plcc = []\n",
    "srcc = []\n",
    "krcc = []\n",
    "for line in lines.split(\"\\n\"):\n",
    "    split = line.split(\" \")\n",
    "    plcc.append((split[0], float(split[2])))\n",
    "    srcc.append((split[0], float(split[4])))\n",
    "    krcc.append((split[0], float(split[6])))\n",
    "    \n",
    "    result[split[0]] = (float(split[2]), float(split[4]), float(split[6]))\n",
    "    \n",
    "result\n",
    "idx = 1\n",
    "print(\"Посчитанные мной\")\n",
    "for pair in sorted(plcc, key = lambda x: x[1], reverse=True):\n",
    "    print(idx, pair[0], pair[1])\n",
    "    idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Данные из статьи\n",
    "1  FSIMc   0.851        \n",
    " 2  PSNR-HA 0.819\n",
    " 3  PSNR-HMA 0.813        \n",
    " 4  FSIM 0.801     \n",
    " 5  MSSIM   0.787         \n",
    " 6  PSNRc   0.687        \n",
    " 7 SSIM 0.637                                        \n",
    " 8 VIFP 0.608                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph: Ox - metric value, Oy - MOS. Blue cross - image in dataset. Black line - fitted logregression\n",
    "plt.plot(metric_scores, mos_scores, \"+\")\n",
    "x = np.arange(0.0, 1.0, 0.005)\n",
    "y = model(torch.tensor(x))\n",
    "plt.plot(x, y.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSIMc\n",
    "MSE\n",
    "epoch 9000, loss 0.4084590971469879\n",
    "tensor(0.8559) \n",
    "\n",
    "PLCC\n",
    "epoch 10000, loss 0.14436256885528564\n",
    "tensor(0.8556)\n",
    "\n",
    "VIFP\n",
    "PLCC\n",
    "tensor(0.7530)\n",
    "\n",
    "MSE\n",
    "epoch1000 loss 0.6762036681175232\n",
    "tensor(0.7519)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict PM lib scores, fit regression, get ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDRLoss(nn.Module):\n",
    "    \"\"\"High dynamic range loss.\"\"\"\n",
    "\n",
    "    def __init__(self, eps=0.01):\n",
    "        \"\"\"Initializes loss with numerical stability epsilon.\"\"\"\n",
    "\n",
    "        super(HDRLoss, self).__init__()\n",
    "        self._eps = eps\n",
    "\n",
    "\n",
    "    def forward(self, denoised, target):\n",
    "        \"\"\"Computes loss by unpacking render buffer.\"\"\"\n",
    "\n",
    "        loss = ((denoised - target) ** 2) / (denoised + self._eps) ** 2\n",
    "        return loss.mean(dim=[1,2,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
