{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Read DF, convert columns to right dtype and filter by `train` and `fold`\n",
    "        df = pd.read_csv(os.path.join(root, f\"merged_datasets_{size}.csv\"))\n",
    "        df = df.astype({\"target\": int, \"fold\": str})\n",
    "        if train:\n",
    "            df = df[(df[\"fold\"] != str(fold)) & (df[\"fold\"] != \"test\") & (df[\"dataset\"].isin(datasets))]\n",
    "        else:\n",
    "            df = df[(df[\"fold\"] == str(fold)) & (df[\"dataset\"].isin(datasets))]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T12:46:21.785878Z",
     "start_time": "2020-07-20T12:46:21.783517Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:09:15.813335Z",
     "start_time": "2020-08-03T09:09:14.447041Z"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import functools\n",
    "\n",
    "import cv2\n",
    "import piq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import albumentations as albu\n",
    "import albumentations.pytorch as albu_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T08:33:24.019541Z",
     "start_time": "2020-08-03T08:33:24.017543Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:09:19.260664Z",
     "start_time": "2020-08-03T09:09:19.249688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:90% !important;}</style>\"))\n",
    "\n",
    "# Fix to be able to import python modules inside a notebook\n",
    "os.chdir('..')\n",
    "\n",
    "# Useful extensions\n",
    "# %load_ext watermark\n",
    "# %watermark -v -n -m -p numpy,torch,albumentations,photosynthesis_metrics\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Nice plot formating\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:09:19.845501Z",
     "start_time": "2020-08-03T09:09:19.720544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs   logs\t    notebooks  reports\t\t test_images.zip  WORKPLAN.md\r\n",
      "data\t  Makefile  old_logs   requirements.txt  tests\r\n",
      "labeling  models    README.md  src\t\t train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training GAN's experiments:\n",
    "\n",
    "GAN runner\n",
    "GAN callback to support custom metrics\n",
    "\n",
    "GAN model (from Skoltech DL course)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse model results to get best checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T08:19:06.930045Z",
     "start_time": "2020-07-30T08:19:06.896131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model with best psnr value 25.5789\n"
     ]
    }
   ],
   "source": [
    "from src.features.models import MODEL_FROM_NAME\n",
    "\n",
    "def get_best_model(task: str, metric: str, mode: str = \"min\", root: str = \"logs\") -> nn.Module:\n",
    "    \"\"\"Returns best model for specific task and metric\n",
    "    Args:\n",
    "        task: One of {`sr`, `denoise`, `deblur`}\n",
    "        metric: Metric name\n",
    "        mode: Find minimum or maximum value\n",
    "        root: Path to folder with logs\n",
    "    \"\"\"\n",
    "    task_folders = []\n",
    "    for folder_name in os.listdir(root):\n",
    "        if task == folder_name.split(\"_\")[0]:\n",
    "            task_folders.append(folder_name)\n",
    "            \n",
    "    if mode == \"min\":\n",
    "        best = np.inf\n",
    "        monitor_op = np.less\n",
    "    elif mode == \"max\":\n",
    "        best = - np.inf\n",
    "        monitor_op = np.greater\n",
    "    else:\n",
    "        raise ValueError(f\"Mode {mode} not defined!\")\n",
    "    \n",
    "    model_name, model_weights = None, None\n",
    "\n",
    "    for folder in task_folders:\n",
    "        # Load checkpoint\n",
    "        checkpoint_path = os.path.join(root, folder, f\"model_{metric}.chpn\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        current = checkpoint[\"value\"]\n",
    "        if monitor_op(current, best):\n",
    "            best = current\n",
    "            model_name = folder.split(\"_\")[2]\n",
    "            model_weights = checkpoint[\"state_dict\"]\n",
    "        \n",
    "    # Load model\n",
    "    model = MODEL_FROM_NAME[model_name]()\n",
    "    model.load_state_dict(model_weights)\n",
    "    print(f\"Found model with best {metric} value {best:.4f}\")\n",
    "    return model\n",
    "       \n",
    "model = get_best_model(task=\"deblur\", metric=\"psnr\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T08:25:39.334762Z",
     "start_time": "2020-07-30T08:25:38.936254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4999, 0.5428, 0.7437,  ..., 0.6626, 0.4843, 0.5072],\n",
       "          [0.4708, 0.4690, 0.6330,  ..., 0.6996, 0.6185, 0.5259],\n",
       "          [0.4090, 0.3908, 0.6269,  ..., 0.7073, 0.6420, 0.5910],\n",
       "          ...,\n",
       "          [0.7245, 0.4985, 0.4155,  ..., 0.2828, 0.2729, 0.4264],\n",
       "          [0.4935, 0.7046, 0.4990,  ..., 0.4395, 0.4466, 0.4762],\n",
       "          [0.4798, 0.6257, 0.6719,  ..., 0.6877, 0.6423, 0.4916]],\n",
       "\n",
       "         [[0.4895, 0.4619, 0.4943,  ..., 0.8595, 0.6318, 0.7945],\n",
       "          [0.4380, 0.4043, 0.4516,  ..., 0.8498, 0.7570, 0.7280],\n",
       "          [0.4426, 0.3638, 0.5839,  ..., 0.7171, 0.6137, 0.7215],\n",
       "          ...,\n",
       "          [0.8938, 0.4837, 0.3751,  ..., 0.2228, 0.2042, 0.3832],\n",
       "          [0.5795, 0.5868, 0.4542,  ..., 0.3856, 0.3783, 0.4453],\n",
       "          [0.4976, 0.6766, 0.6273,  ..., 0.4947, 0.6034, 0.4811]],\n",
       "\n",
       "         [[0.7272, 0.4917, 0.6660,  ..., 0.7403, 0.6129, 0.4999],\n",
       "          [0.7777, 0.4782, 0.4875,  ..., 0.7840, 0.5016, 0.4995],\n",
       "          [0.4947, 0.4366, 0.8937,  ..., 0.4969, 0.5864, 0.7092],\n",
       "          ...,\n",
       "          [0.8957, 0.6218, 0.3774,  ..., 0.3470, 0.2759, 0.3994],\n",
       "          [0.5493, 0.9036, 0.8075,  ..., 0.4280, 0.4304, 0.4054],\n",
       "          [0.5831, 0.7565, 0.8739,  ..., 0.4946, 0.6356, 0.4865]]]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(1,3, 288, 128)\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:34:41.484937Z",
     "start_time": "2020-07-30T07:34:41.481742Z"
    }
   },
   "source": [
    "# Inference images into separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:56:55.612910Z",
     "start_time": "2020-07-30T07:56:55.608351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f\"{i:04d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T08:00:19.315906Z",
     "start_time": "2020-07-30T08:00:19.312431Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:09:28.044282Z",
     "start_time": "2020-08-03T09:09:27.981817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inference selected images\n",
    "from src.data.datasets import DIV2K\n",
    "from PIL import Image\n",
    "\n",
    "# Images used in paper `Comparison of Image Quality Models for Optimization of Image Processing Systems`\n",
    "INDICES = [3, 5, 8, 11, 18, 21, 22, 24, 34, 49, 54, 55, 60, 64, 68, \n",
    "#            69, 82, 83, 88\n",
    "          ]\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference_model(task: str, metric: str, mode: str = \"min\", root: str = \"logs\"):\n",
    "    \n",
    "    # Create output folder\n",
    "    output_path = f\"data/processed/{task}/{metric}\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Find best model\n",
    "    model = get_best_model(task, metric, mode, root).cuda()\n",
    "    \n",
    "    # Get augmentations\n",
    "    NORM_TO_TENSOR = albu.Compose([\n",
    "        albu.Normalize(mean=[0., 0., 0.], std=[1., 1., 1.], ), # to [0, 1]\n",
    "        albu_pt.ToTensorV2()],\n",
    "        additional_targets={\"mask\": \"image\"})\n",
    "    \n",
    "    if task == \"deblur\":\n",
    "        TASK_AUG = albu.OneOf([\n",
    "            albu.Blur(blur_limit=(3, 5)),\n",
    "            albu.GaussianBlur(blur_limit=(3, 5)),\n",
    "        ], p=1.0)\n",
    "    elif task == \"denoise\":\n",
    "        TASK_AUG = albu.OneOf([\n",
    "            albu.MultiplicativeNoise(multiplier=(0.75, 1.25), per_channel=True, elementwise=True),\n",
    "        ], p=1.0)\n",
    "    elif task == \"sr\":\n",
    "        TASK_AUG = albu.Downscale(\n",
    "            scale_min=0.5, scale_max=0.5, interpolation=cv2.INTER_CUBIC, always_apply=True)\n",
    "        \n",
    "    transform = albu.Compose([\n",
    "        TASK_AUG,\n",
    "        NORM_TO_TENSOR,\n",
    "    ])\n",
    "    \n",
    "    dataset = DIV2K(train=False, transform=transform)\n",
    "    \n",
    "    for i, idx in enumerate(INDICES):\n",
    "        input, target = dataset[idx]\n",
    "        \n",
    "        # Add batch dimension\n",
    "        input, target = input.unsqueeze(0).cuda(), target.unsqueeze(0).cuda()\n",
    "        _, _, H, W = input.shape\n",
    "\n",
    "        # It's important for Unet to have image with size dividible by 32, so bad image manuallu and then crop\n",
    "        H_pad, W_pad = (32 - H % 32) % 32, (32 - W % 32) % 32\n",
    "        \n",
    "        input = torch.nn.functional.pad(input, pad=(0, W_pad, 0, H_pad))\n",
    "        target = torch.nn.functional.pad(input, pad=(0, W_pad, 0, H_pad))\n",
    "#         print(input.shape, target.shape)\n",
    "        \n",
    "        # Inference\n",
    "        output = model(input)\n",
    "        \n",
    "        #Save\n",
    "        np_array = output.squeeze()[:, : H, : W].permute(1,2,0).cpu().numpy() * 255\n",
    "        np_array = cv2.cvtColor(np_array, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(f\"{output_path}/{i:02d}.jpeg\", np_array)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T08:35:17.913909Z",
     "start_time": "2020-07-30T08:35:13.529325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model with best psnr value 25.3820\n"
     ]
    }
   ],
   "source": [
    "inference_model(task=\"denoise\", metric=\"psnr\", mode=\"max\")\n",
    "\n",
    "# for idx in indexes:\n",
    "    \n",
    "#     plt.imshow(dataset[idx][0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:09:29.602802Z",
     "start_time": "2020-08-03T09:09:29.596512Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"psnr\", \n",
    "    \"ssim\",\n",
    "    \"ms-ssim\",\n",
    "    \"ms-gmsdc\",\n",
    "    \"fsimc\",\n",
    "    \"vsi\",\n",
    "    \"mdsi\",\n",
    "#     \"vifp\",\n",
    "    \"content_vgg16_ap\",\n",
    "    \"style_vgg16\",\n",
    "    \"lpips\",\n",
    "    \"dists\",\n",
    "    \"brisque\",\n",
    "#     \"is_metric_vgg16\",\n",
    "#     \"is_vgg16\",\n",
    "    \"kid_vgg16\",\n",
    "    \"fid_vgg16\",\n",
    "    \"msid_vgg16\"\n",
    "]\n",
    "\n",
    "MODE_FROM_NAME = {\n",
    "    # Full Reference\n",
    "    \"mae\": \"min\",\n",
    "    \"mse\": \"min\",\n",
    "    \"psnr\": \"max\",\n",
    "    \"psnr_y\": \"max\",\n",
    "    \"ssim\": \"max\",\n",
    "    \"ms-ssim\": \"max\",\n",
    "    \"vifp\": \"max\",\n",
    "    \"vifp_2\": \"max\",\n",
    "    \"gmsd\": \"min\",\n",
    "    \"ms-gmsd\": \"min\",\n",
    "    \"ms-gmsdc\": \"min\",\n",
    "    \"fsim\": \"max\",\n",
    "    \"fsimc\": \"max\",\n",
    "    \"vsi\": \"max\",\n",
    "    \"mdsi\": \"max\",\n",
    "\n",
    "    \"content_vgg16\": \"min\",\n",
    "    \"content_vgg16_ap\": \"min\",\n",
    "\n",
    "    \"style_vgg16\": \"min\",\n",
    "    \n",
    "    \"lpips\": \"min\",\n",
    "    \"dists\": \"min\",\n",
    "\n",
    "    # No reference\n",
    "    \"brisque\": \"min\",\n",
    "\n",
    "    # Distribution based metrics\n",
    "    \"fid_vgg16\": \"min\",\n",
    "    \"kid_vgg16\": \"min\",\n",
    "    \"gs_vgg16\": \"min\",\n",
    "    \"is_metric_vgg16\": \"min\",\n",
    "    \"is_vgg16\": \"min\",\n",
    "    \"msid_vgg16\": \"min\",\n",
    "}\n",
    "\n",
    "tasks = [\n",
    "#     \"denoise\",\n",
    "#     \"deblur\",\n",
    "    \"sr\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T08:36:54.432965Z",
     "start_time": "2020-07-30T08:36:23.761704Z"
    },
    "code_folding": [
     4
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model with best psnr value 25.5752\n",
      "Found model with best ssim value 0.7910\n",
      "Found model with best ms-ssim value 0.9667\n",
      "Found model with best ms-gmsdc value 0.0583\n",
      "Found model with best fsimc value 0.8802\n",
      "Found model with best vsi value 0.9622\n",
      "Found model with best mdsi value 0.5007\n",
      "Found model with best vifp value 0.7761\n",
      "Found model with best content_vgg16_ap value 0.1685\n",
      "Found model with best style_vgg16 value 157959824.0000\n",
      "Found model with best lpips value 0.1944\n",
      "Found model with best dists value 0.1459\n",
      "Found model with best brisque value 41.2568\n",
      "Found model with best is_metric_vgg16 value 1.1299\n",
      "Found model with best is_vgg16 value 0.5701\n",
      "Found model with best kid_vgg16 value 0.0191\n",
      "Found model with best fid_vgg16 value 14.2605\n",
      "Found model with best msid_vgg16 value 11.5287\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    for metric in metrics:\n",
    "        inference_model(task=task, metric=metric, mode=MODE_FROM_NAME[metric])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:09:36.083723Z",
     "start_time": "2020-08-03T09:09:36.079807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15 3\n"
     ]
    }
   ],
   "source": [
    "NUM_METRICS = len(metrics)\n",
    "NUM_IMAGES = len(INDICES)\n",
    "NUM_TASKS = 3  # SR, Deblur, Denoise\n",
    "print(NUM_METRICS, NUM_IMAGES, NUM_TASKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:25:41.847592Z",
     "start_time": "2020-08-03T11:25:41.834421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'left_img': '/home/zakirov/repoz/metrics-comparison/data/processed/deblur/psnr/00.jpeg', 'right_img': 'http://38b5b1a77e0b.eu.ngrok.io/data/processed/deblur/ssim/00.jpeg', 'task': 'deblur', 'left_metric': 'psnr', 'right_metric': 'ssim', 'image_id': 0}, {'left_img': '/home/zakirov/repoz/metrics-comparison/data/processed/deblur/psnr/00.jpeg', 'right_img': 'http://38b5b1a77e0b.eu.ngrok.io/data/processed/deblur/ms-ssim/00.jpeg', 'task': 'deblur', 'left_metric': 'psnr', 'right_metric': 'ms-ssim', 'image_id': 0}, {'left_img': '/home/zakirov/repoz/metrics-comparison/data/processed/deblur/ssim/00.jpeg', 'right_img': 'http://38b5b1a77e0b.eu.ngrok.io/data/processed/deblur/ms-ssim/00.jpeg', 'task': 'deblur', 'left_metric': 'ssim', 'right_metric': 'ms-ssim', 'image_id': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Create JSON file for label studio\n",
    "# 1. All possible permutation pairs for all images and tasks\n",
    "# 2. Total number: C^NUM_METRICS_2 * NUM_IMAGES * NUM_TASKS ~ 4700 for 15 metrics, 15 images and 3 tasks\n",
    "import itertools\n",
    "PORT = 6113\n",
    "NGROK = \"http://38b5b1a77e0b.eu.ngrok.io\"\n",
    "LEFT_LABEL = \"left_img\"\n",
    "RIGHT_LABEL = \"right_img\"\n",
    "\n",
    "\n",
    "ROOT = \"data/images\"\n",
    "def create_json(task=\"deblur\", image_id=0, metrics_list=[\"psnr\", \"ssim\", \"ms-ssim\"]):\n",
    "    # Read all relevant files\n",
    "    path = os.path.join(\"data/processed\", task)\n",
    "\n",
    "    files = []\n",
    "    for metric in metrics_list:\n",
    "        file = os.path.join(path, metric, f\"{image_id:02d}.jpeg\")\n",
    "        files.append(file)\n",
    "        \n",
    "    result = []\n",
    "    # Create tasks file\n",
    "    for (left, right) in itertools.combinations(files, 2):\n",
    "        d = {\n",
    "#             LEFT_LABEL: os.path.join(NGROK, left),\n",
    "            LEFT_LABEL: os.path.abspath(left),\n",
    "            RIGHT_LABEL: os.path.join(NGROK, right),\n",
    "            \"task\": task,\n",
    "            \"left_metric\": left.split(\"/\")[3],\n",
    "            \"right_metric\": right.split(\"/\")[3],\n",
    "            \"image_id\": image_id,\n",
    "        }\n",
    "        result.append(d)\n",
    "    return result\n",
    "        \n",
    "    \n",
    "#     print(list(combinations))\n",
    "\n",
    "    \n",
    "# for task in tasks:\n",
    "#     pass\n",
    "result = create_json()\n",
    "with open(\"data/tasks.json\", \"w\") as f:\n",
    "    json.dump(result, f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:19:32.697388Z",
     "start_time": "2020-08-03T09:19:32.694507Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"0\": {\n",
    "    \"id\": 0,\n",
    "    \"data\": {\n",
    "      \"image\": \"http://localhost:8080/data/upload/d68e7813b0a6e4746757e065c3230fcf-16.jpeg\"\n",
    "    }\n",
    "  },\n",
    "  \"1\": {\n",
    "    \"id\": 1,\n",
    "    \"data\": {\n",
    "      \"image\": \"http://localhost:8080/data/upload/ef189674482810635345c9b0cba26dbb-17.jpeg\"\n",
    "    }\n",
    "  },\n",
    "  \"2\": {\n",
    "    \"id\": 2,\n",
    "    \"data\": {\n",
    "      \"image\": \"http://localhost:8080/data/upload/54b632673940f9198546683d6aa3eee7-18.jpeg\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T09:20:37.634806Z",
     "start_time": "2020-08-03T09:20:37.630746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": {\"id\": 0, \"data\": {\"image\": \"http://localhost:8080/data/upload/d68e7813b0a6e4746757e065c3230fcf-16.jpeg\"}}, \"1\": {\"id\": 1, \"data\": {\"image\": \"http://localhost:8080/data/upload/ef189674482810635345c9b0cba26dbb-17.jpeg\"}}, \"2\": {\"id\": 2, \"data\": {\"image\": \"http://localhost:8080/data/upload/54b632673940f9198546683d6aa3eee7-18.jpeg\"}}}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = json.dumps(data)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:20:28.264613Z",
     "start_time": "2020-07-27T10:20:28.260587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(metrics))\n",
    "\n",
    "tasks = 3\n",
    "\n",
    "images = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T10:24:54.130766Z",
     "start_time": "2020-07-22T10:24:54.121229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96])\n",
      "torch.Size([3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "from src.data import crop_patches\n",
    "\n",
    "target = torch.rand(4, 3, 128, 128)\n",
    "target_patches = crop_patches(target, size=96, stride=32)\n",
    "print(target_patches.shape)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(target_patches)\n",
    "print(dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T09:27:17.754968Z",
     "start_time": "2020-07-22T09:27:17.748068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSNR()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PSNR(torch.nn.modules.loss._Loss):\n",
    "    def __init(self, data_range=1.0, reduction='mean', convert_to_greyscale: bool = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.metric = functools.partial(\n",
    "            piq.psnr, data_range=data_range, reduction=reduction, convert_to_greyscale=convert_to_greyscale)\n",
    "\n",
    "    def forward(self, prediction: torch.Tensor, target: torch.Tensor):\n",
    "        self.metric(prediction, target)\n",
    "\n",
    "\n",
    "kwargs = {'data_range': 1.0, 'convert_to_greyscale': False},\n",
    "PSNR(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:18:35.880350Z",
     "start_time": "2020-07-22T07:18:35.869249Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-615ce959ff06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGMSDLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "issubclass(piq.GMSDLoss, torch.nn.modules.loss._Loss)\n",
    "issubclass(piq.fsim, torch.nn.modules.loss._Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T08:20:32.604205Z",
     "start_time": "2020-07-23T08:20:32.599787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 4, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3, 4, 4, 2)\n",
    "res = torch.split(a, split_size_or_sections=1, dim=4)\n",
    "res[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:11:49.947120Z",
     "start_time": "2020-07-22T07:11:49.940629Z"
    }
   },
   "outputs": [],
   "source": [
    "piq.multi_scale_ssim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:59:38.273860Z",
     "start_time": "2020-07-22T06:59:37.949935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = torch.rand(4, 3, 128, 128)\n",
    "piq.MultiScaleGMSDLoss()(prediction, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T13:46:41.932086Z",
     "start_time": "2020-07-21T13:46:41.885686Z"
    }
   },
   "outputs": [],
   "source": [
    "piq.ContentLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T08:53:33.248382Z",
     "start_time": "2020-07-15T08:53:33.245013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_3_0.23.chpn'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"model_{ep}_{metric:.2f}.chpn\"\n",
    "a.format(ep=3, metric=0.234556436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:24:23.281249Z",
     "start_time": "2020-07-22T06:24:23.276839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': ['conv1_2', 'conv2_2', 'conv3_4', 'conv4_4', 'conv5_4'],\n",
       " 'weights': [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       " 'normalize_features': True,\n",
       " 'reduction': 'none'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"feature_extractor\": 'vgg19',\n",
    "    \"layers\": ['conv1_2', 'conv2_2', 'conv3_4', 'conv4_4', 'conv5_4'],\n",
    "    \"weights\": [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "    \"normalize_features\": True,\n",
    "    \"reduction\": 'none',\n",
    "}\n",
    "\n",
    "kwargs.pop(\"feature_extractor\")\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # DummyAverageMeter is added to the end, so just delete last part\n",
    "        counter = 0\n",
    "        for i, metric in enumerate(self.state.metric_meters):\n",
    "            if isinstance(metric, AverageMeter):\n",
    "                metric.reset()\n",
    "            else:\n",
    "                counter += 1\n",
    "        self.state.metric_meters = self.state.metric_meters[:-counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T12:08:24.473959Z",
     "start_time": "2020-07-24T12:08:24.470943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<function vif_p at 0x7f59f1780d08>, reduction='none') test\n"
     ]
    }
   ],
   "source": [
    "reduction = 'none'\n",
    "f = functools.partial(piq.vif_p, reduction=reduction)\n",
    "f.name = \"test\"\n",
    "print(f, f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T12:02:14.696380Z",
     "start_time": "2020-07-24T12:02:14.691286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.A object at 0x7f59d08592e8>, <__main__.A object at 0x7f59d0859860>, <__main__.B object at 0x7f59d08597f0>, <__main__.B object at 0x7f59d08598d0>, <__main__.B object at 0x7f59d0859898>, <__main__.A object at 0x7f59d0859828>]\n",
      "A reseted\n",
      "A reseted\n",
      "A reseted\n",
      "[<__main__.A object at 0x7f59d08592e8>, <__main__.A object at 0x7f59d0859860>, <__main__.A object at 0x7f59d0859828>]\n"
     ]
    }
   ],
   "source": [
    "class A():\n",
    "    def reset(self):\n",
    "        print(\"A reseted\")\n",
    "\n",
    "\n",
    "class B():\n",
    "    def reset(self):\n",
    "        print(\"B reseted\")\n",
    "\n",
    "class State:\n",
    "    def __init__(self, metric_meters):\n",
    "        self.metric_meters = metric_meters\n",
    "\n",
    "metric_meters = [A(), A(), B(), B(), B(), A()]\n",
    "print(metric_meters)\n",
    "state = State(metric_meters)\n",
    "\n",
    "state.metric_meters = [m for m in state.metric_meters if isinstance(m, A)]\n",
    "for metric in state.metric_meters:\n",
    "    metric.reset()\n",
    "\n",
    "# omelist = [x for x in somelist if not determine(x)]\n",
    "\n",
    "# for i, metric in enumerate(state.metric_meters):\n",
    "#     if isinstance(metric, A):\n",
    "#         metric.reset()\n",
    "#     elif isinstance(metric, B):\n",
    "#         print(\"Deleting B\")\n",
    "#         del state.metric_meters[i]\n",
    "print(state.metric_meters)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:27:05.290690Z",
     "start_time": "2020-07-24T11:27:05.215448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7687)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "METRIC_FROM_NAME = {\n",
    "    # Full Reference\n",
    "    \"psnr\": functools.partial(\n",
    "        piq.psnr),\n",
    "}\n",
    "\n",
    "def get_metric(name, reduction='none'):\n",
    "    metric = METRIC_FROM_NAME[name]\n",
    "    return functools.partial(metric, reduction=reduction)\n",
    "    \n",
    "prediction = torch.rand(4, 3, 128, 128)\n",
    "target = torch.rand(4, 3, 128, 128)\n",
    "\n",
    "get_metric(\"psnr\")(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:41:02.240900Z",
     "start_time": "2020-07-24T11:40:56.629790Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [piq.ContentLoss(), piq.StyleLoss(), piq.LPIPS(), piq.DISTS(), piq.GMSDLoss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[07-24 20:48] - Best loss: 0.0394\n",
    "[07-24 20:48] - Best psnr: 25.0806\n",
    "[07-24 20:48] - Best ssim: 0.7546\n",
    "[07-24 20:48] - Best ms-ssim: 0.9332\n",
    "[07-24 20:48] - Best gmsd: 0.0846\n",
    "[07-24 20:48] - Best ms-gmsd: 0.0816\n",
    "[07-24 20:48] - Best ms-gmsdc: 0.0681\n",
    "[07-24 20:48] - Best fsim: 0.8802\n",
    "[07-24 20:48] - Best fsimc: 0.8744\n",
    "[07-24 20:48] - Best vsi: 0.9544\n",
    "[07-24 20:48] - Best mdsi: 0.4146\n",
    "[07-24 20:48] - Best vifp: 0.9085\n",
    "[07-24 20:48] - Best content_vgg16: 0.2474\n",
    "[07-24 20:48] - Best content_vgg19: 0.2679\n",
    "[07-24 20:48] - Best content_vgg16_ap: 0.2176\n",
    "[07-24 20:48] - Best content_vgg19_ap: 0.2257\n",
    "[07-24 20:48] - Best style_vgg16: 9222874.0769\n",
    "[07-24 20:48] - Best style_vgg19: 7961090.4615\n",
    "[07-24 20:48] - Best lpips: 0.2275\n",
    "[07-24 20:48] - Best dists: 0.1868\n",
    "[07-24 20:48] - Best brisque: 37.7652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[07-27 15:22] - Best loss: 0.0353\n",
    "[07-27 15:22] - Best psnr: 25.4831\n",
    "[07-27 15:22] - Best ssim: 0.7822\n",
    "[07-27 15:22] - Best ms-ssim: 0.9491\n",
    "[07-27 15:22] - Best gmsd: 0.0853\n",
    "[07-27 15:22] - Best ms-gmsd: 0.0827\n",
    "[07-27 15:22] - Best ms-gmsdc: 0.0693\n",
    "[07-27 15:22] - Best fsim: 0.8753\n",
    "[07-27 15:22] - Best fsimc: 0.8733\n",
    "[07-27 15:22] - Best vsi: 0.9596\n",
    "[07-27 15:22] - Best mdsi: 0.4467\n",
    "[07-27 15:22] - Best vifp: 0.8642\n",
    "[07-27 15:22] - Best content_vgg16_ap: 0.1814\n",
    "[07-27 15:22] - Best style_vgg16: 147372154.8571\n",
    "[07-27 15:22] - Best lpips: 0.2060\n",
    "[07-27 15:22] - Best dists: 0.1557\n",
    "[07-27 15:22] - Best brisque: 45.1469\n",
    "[07-27 15:22] - Best is_metric_vgg16: 1.1791\n",
    "[07-27 15:22] - Best is_vgg16: 0.4978\n",
    "[07-27 15:22] - Best kid_vgg16: 0.0180\n",
    "[07-27 15:22] - Best fid_vgg16: 14.8280\n",
    "[07-27 15:22] - Best msid_vgg16: 8.8804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[07-27 16:27] - Best loss: 0.0036\n",
    "[07-27 16:27] - Best psnr: 25.3338\n",
    "[07-27 16:27] - Best ssim: 0.7586\n",
    "[07-27 16:27] - Best ms-ssim: 0.9371\n",
    "[07-27 16:27] - Best gmsd: 0.0873\n",
    "[07-27 16:27] - Best ms-gmsd: 0.0832\n",
    "[07-27 16:27] - Best ms-gmsdc: 0.0696\n",
    "[07-27 16:27] - Best fsim: 0.8803\n",
    "[07-27 16:27] - Best fsimc: 0.8775\n",
    "[07-27 16:27] - Best vsi: 0.9612\n",
    "[07-27 16:27] - Best mdsi: 0.4124\n",
    "[07-27 16:27] - Best vifp: 0.9856\n",
    "[07-27 16:27] - Best content_vgg16_ap: 0.1994\n",
    "[07-27 16:27] - Best style_vgg16: 56819345.4286\n",
    "[07-27 16:27] - Best lpips: 0.2112\n",
    "[07-27 16:27] - Best dists: 0.1431\n",
    "[07-27 16:27] - Best brisque: 36.5921\n",
    "[07-27 16:27] - Best is_metric_vgg16: 1.2533\n",
    "[07-27 16:27] - Best is_vgg16: 0.3236\n",
    "[07-27 16:27] - Best kid_vgg16: 0.0104\n",
    "[07-27 16:27] - Best fid_vgg16: 11.7871\n",
    "[07-27 16:27] - Best msid_vgg16: 4.0915\n",
    "[07-27 16:27] - Finished training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[07-27 17:22] - Best loss: 0.0567\n",
    "[07-27 17:22] - Best psnr: 24.6242\n",
    "[07-27 17:22] - Best ssim: 0.7714\n",
    "[07-27 17:22] - Best ms-ssim: 0.9410\n",
    "[07-27 17:22] - Best gmsd: 0.0834\n",
    "[07-27 17:22] - Best ms-gmsd: 0.0799\n",
    "[07-27 17:22] - Best ms-gmsdc: 0.0663\n",
    "[07-27 17:22] - Best fsim: 0.8866\n",
    "[07-27 17:22] - Best fsimc: 0.8804\n",
    "[07-27 17:22] - Best vsi: 0.9596\n",
    "[07-27 17:22] - Best mdsi: 0.4374\n",
    "[07-27 17:22] - Best vifp: 0.9039\n",
    "[07-27 17:22] - Best content_vgg16_ap: 0.2017\n",
    "[07-27 17:22] - Best style_vgg16: 290767860.0000\n",
    "[07-27 17:22] - Best lpips: 0.2258\n",
    "[07-27 17:22] - Best dists: 0.1545\n",
    "[07-27 17:22] - Best brisque: 34.5464\n",
    "[07-27 17:22] - Best is_metric_vgg16: 1.3126\n",
    "[07-27 17:22] - Best is_vgg16: 0.3683\n",
    "[07-27 17:22] - Best kid_vgg16: 0.0117\n",
    "[07-27 17:22] - Best fid_vgg16: 13.4920\n",
    "[07-27 17:22] - Best msid_vgg16: 7.6096\n",
    "[07-27 17:22] - Finished training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
