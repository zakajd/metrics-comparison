import os
from functools import partial, reduce


import torch
from torchvision.transforms import Compose
from torch.utils.data import Dataset, random_split
from torch.utils.data import DataLoader

def get_dataloader(
    datasets,
    transforms=None,
    batch_size=16, 
    train=True,
    train_size=0.8,
    sample_length=24000,
    **kwargs
    ):
    """Returns data from several datasets
    
    Args:
        datasets (list): Datset names, should be in {"arctic", "ljspeech", "vctk"}.
        dataset_class (torch.utils.data): One of {"AudioDataset", "AudioMelDataset"}
        resample (bool): Flag to resample with given sample rate.
        sampling_rate (int): Parameter for torchaudio.transforms.Resample.
        batch_size (int): Size of batch generated by dataloader.
        train (bool): Return train data if `True`, validation data if `False`.
        train_size (float): Part of data used for training
        sample_length (int): Maximum length of a waveform segment. Fixed size is needed for batching.

    Returns:
        dataloader
    """
    # Get datasets
    all_datasets = []

    if "mnist" in datasets:
        # dataset = dataset_class("datasets/cmu_arctic", transforms, resample, sampling_rate, **kwargs)

        # train_length=int(len(dataset) * train_size)
        # val_length=len(dataset) - train_length
        # train_d, val_d = random_split(dataset, (train_length, val_length))

        # all_datasets.append(train_d if train else val_d)
 
    # Concat all datasets into one
    all_datasets = reduce(lambda x, y: x + y, all_datasets)

    # without `drop_last` last batch consists of 1 element and BN fails TODO(zakajd): Remove this ???
    if train:
        dataloader = DataLoader(
            all_datasets, 
            batch_size=batch_size, 
            shuffle=True, 
            num_workers=8, 
            drop_last=True, 
            pin_memory=True)
    else:
        dataloader = DataLoader(
            all_datasets, 
            batch_size=1,
            shuffle=False, 
            num_workers=8,
            pin_memory=True)


    print(f"\nUsing datasets: {datasets}. {'Train' if train else 'Validation'} size: {len(all_datasets)}.")
    return dataloader